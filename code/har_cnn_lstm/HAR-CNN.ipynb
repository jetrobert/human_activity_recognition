{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"train\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 32, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=4, strides=4, padding='same')\n",
    "    \n",
    "    # (batch, 32, 18) --> (batch, 8, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=4, strides=4, padding='same')\n",
    "    \n",
    "    # (batch, 8, 36) --> (batch, 2, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=4, strides=4, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_3, (-1, 2*72))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/500 Iteration: 5 Train loss: 1.967811 Train acc: 0.153333\n",
      "Epoch: 1/500 Iteration: 10 Train loss: 1.835192 Train acc: 0.211667\n",
      "Epoch: 1/500 Iteration: 10 Validation loss: 1.732057 Validation acc: 0.267778\n",
      "Epoch: 1/500 Iteration: 15 Train loss: 1.734496 Train acc: 0.256667\n",
      "Epoch: 2/500 Iteration: 20 Train loss: 1.689356 Train acc: 0.310000\n",
      "Epoch: 2/500 Iteration: 20 Validation loss: 1.642755 Validation acc: 0.393333\n",
      "Epoch: 2/500 Iteration: 25 Train loss: 1.622118 Train acc: 0.363333\n",
      "Epoch: 3/500 Iteration: 30 Train loss: 1.572803 Train acc: 0.420000\n",
      "Epoch: 3/500 Iteration: 30 Validation loss: 1.524108 Validation acc: 0.579444\n",
      "Epoch: 3/500 Iteration: 35 Train loss: 1.504116 Train acc: 0.453333\n",
      "Epoch: 4/500 Iteration: 40 Train loss: 1.422041 Train acc: 0.496667\n",
      "Epoch: 4/500 Iteration: 40 Validation loss: 1.359606 Validation acc: 0.644444\n",
      "Epoch: 4/500 Iteration: 45 Train loss: 1.319526 Train acc: 0.535000\n",
      "Epoch: 5/500 Iteration: 50 Train loss: 1.270306 Train acc: 0.565000\n",
      "Epoch: 5/500 Iteration: 50 Validation loss: 1.160483 Validation acc: 0.672222\n",
      "Epoch: 6/500 Iteration: 55 Train loss: 1.204488 Train acc: 0.555000\n",
      "Epoch: 6/500 Iteration: 60 Train loss: 1.092478 Train acc: 0.565000\n",
      "Epoch: 6/500 Iteration: 60 Validation loss: 0.969280 Validation acc: 0.701111\n",
      "Epoch: 7/500 Iteration: 65 Train loss: 0.958148 Train acc: 0.646667\n",
      "Epoch: 7/500 Iteration: 70 Train loss: 0.903659 Train acc: 0.656667\n",
      "Epoch: 7/500 Iteration: 70 Validation loss: 0.821570 Validation acc: 0.721111\n",
      "Epoch: 8/500 Iteration: 75 Train loss: 0.880934 Train acc: 0.640000\n",
      "Epoch: 8/500 Iteration: 80 Train loss: 0.832534 Train acc: 0.678333\n",
      "Epoch: 8/500 Iteration: 80 Validation loss: 0.722847 Validation acc: 0.745556\n",
      "Epoch: 9/500 Iteration: 85 Train loss: 0.797838 Train acc: 0.678333\n",
      "Epoch: 9/500 Iteration: 90 Train loss: 0.722941 Train acc: 0.716667\n",
      "Epoch: 9/500 Iteration: 90 Validation loss: 0.658935 Validation acc: 0.756111\n",
      "Epoch: 10/500 Iteration: 95 Train loss: 0.759136 Train acc: 0.696667\n",
      "Epoch: 11/500 Iteration: 100 Train loss: 0.714492 Train acc: 0.703333\n",
      "Epoch: 11/500 Iteration: 100 Validation loss: 0.607697 Validation acc: 0.774444\n",
      "Epoch: 11/500 Iteration: 105 Train loss: 0.682118 Train acc: 0.725000\n",
      "Epoch: 12/500 Iteration: 110 Train loss: 0.622755 Train acc: 0.755000\n",
      "Epoch: 12/500 Iteration: 110 Validation loss: 0.566014 Validation acc: 0.789444\n",
      "Epoch: 12/500 Iteration: 115 Train loss: 0.630622 Train acc: 0.768333\n",
      "Epoch: 13/500 Iteration: 120 Train loss: 0.630977 Train acc: 0.746667\n",
      "Epoch: 13/500 Iteration: 120 Validation loss: 0.532508 Validation acc: 0.801667\n",
      "Epoch: 13/500 Iteration: 125 Train loss: 0.575248 Train acc: 0.758333\n",
      "Epoch: 14/500 Iteration: 130 Train loss: 0.610437 Train acc: 0.743333\n",
      "Epoch: 14/500 Iteration: 130 Validation loss: 0.502702 Validation acc: 0.812222\n",
      "Epoch: 14/500 Iteration: 135 Train loss: 0.577905 Train acc: 0.758333\n",
      "Epoch: 15/500 Iteration: 140 Train loss: 0.590098 Train acc: 0.746667\n",
      "Epoch: 15/500 Iteration: 140 Validation loss: 0.476263 Validation acc: 0.818333\n",
      "Epoch: 16/500 Iteration: 145 Train loss: 0.548202 Train acc: 0.776667\n",
      "Epoch: 16/500 Iteration: 150 Train loss: 0.568680 Train acc: 0.765000\n",
      "Epoch: 16/500 Iteration: 150 Validation loss: 0.455213 Validation acc: 0.824444\n",
      "Epoch: 17/500 Iteration: 155 Train loss: 0.457068 Train acc: 0.833333\n",
      "Epoch: 17/500 Iteration: 160 Train loss: 0.473993 Train acc: 0.813333\n",
      "Epoch: 17/500 Iteration: 160 Validation loss: 0.436895 Validation acc: 0.831667\n",
      "Epoch: 18/500 Iteration: 165 Train loss: 0.527615 Train acc: 0.768333\n",
      "Epoch: 18/500 Iteration: 170 Train loss: 0.456230 Train acc: 0.820000\n",
      "Epoch: 18/500 Iteration: 170 Validation loss: 0.418164 Validation acc: 0.845000\n",
      "Epoch: 19/500 Iteration: 175 Train loss: 0.483705 Train acc: 0.781667\n",
      "Epoch: 19/500 Iteration: 180 Train loss: 0.468724 Train acc: 0.826667\n",
      "Epoch: 19/500 Iteration: 180 Validation loss: 0.400534 Validation acc: 0.847222\n",
      "Epoch: 20/500 Iteration: 185 Train loss: 0.463930 Train acc: 0.810000\n",
      "Epoch: 21/500 Iteration: 190 Train loss: 0.437601 Train acc: 0.830000\n",
      "Epoch: 21/500 Iteration: 190 Validation loss: 0.390606 Validation acc: 0.853333\n",
      "Epoch: 21/500 Iteration: 195 Train loss: 0.468064 Train acc: 0.813333\n",
      "Epoch: 22/500 Iteration: 200 Train loss: 0.420780 Train acc: 0.831667\n",
      "Epoch: 22/500 Iteration: 200 Validation loss: 0.379502 Validation acc: 0.858333\n",
      "Epoch: 22/500 Iteration: 205 Train loss: 0.409181 Train acc: 0.846667\n",
      "Epoch: 23/500 Iteration: 210 Train loss: 0.451107 Train acc: 0.813333\n",
      "Epoch: 23/500 Iteration: 210 Validation loss: 0.369199 Validation acc: 0.860000\n",
      "Epoch: 23/500 Iteration: 215 Train loss: 0.390013 Train acc: 0.846667\n",
      "Epoch: 24/500 Iteration: 220 Train loss: 0.416887 Train acc: 0.821667\n",
      "Epoch: 24/500 Iteration: 220 Validation loss: 0.358599 Validation acc: 0.864444\n",
      "Epoch: 24/500 Iteration: 225 Train loss: 0.412408 Train acc: 0.833333\n",
      "Epoch: 25/500 Iteration: 230 Train loss: 0.387682 Train acc: 0.836667\n",
      "Epoch: 25/500 Iteration: 230 Validation loss: 0.350443 Validation acc: 0.867222\n",
      "Epoch: 26/500 Iteration: 235 Train loss: 0.392563 Train acc: 0.836667\n",
      "Epoch: 26/500 Iteration: 240 Train loss: 0.453767 Train acc: 0.825000\n",
      "Epoch: 26/500 Iteration: 240 Validation loss: 0.347798 Validation acc: 0.868889\n",
      "Epoch: 27/500 Iteration: 245 Train loss: 0.347796 Train acc: 0.871667\n",
      "Epoch: 27/500 Iteration: 250 Train loss: 0.362720 Train acc: 0.863333\n",
      "Epoch: 27/500 Iteration: 250 Validation loss: 0.337695 Validation acc: 0.872222\n",
      "Epoch: 28/500 Iteration: 255 Train loss: 0.395749 Train acc: 0.841667\n",
      "Epoch: 28/500 Iteration: 260 Train loss: 0.357298 Train acc: 0.870000\n",
      "Epoch: 28/500 Iteration: 260 Validation loss: 0.334337 Validation acc: 0.868333\n",
      "Epoch: 29/500 Iteration: 265 Train loss: 0.340646 Train acc: 0.866667\n",
      "Epoch: 29/500 Iteration: 270 Train loss: 0.359611 Train acc: 0.863333\n",
      "Epoch: 29/500 Iteration: 270 Validation loss: 0.329330 Validation acc: 0.870556\n",
      "Epoch: 30/500 Iteration: 275 Train loss: 0.391723 Train acc: 0.823333\n",
      "Epoch: 31/500 Iteration: 280 Train loss: 0.349402 Train acc: 0.858333\n",
      "Epoch: 31/500 Iteration: 280 Validation loss: 0.322582 Validation acc: 0.875556\n",
      "Epoch: 31/500 Iteration: 285 Train loss: 0.409130 Train acc: 0.845000\n",
      "Epoch: 32/500 Iteration: 290 Train loss: 0.306257 Train acc: 0.876667\n",
      "Epoch: 32/500 Iteration: 290 Validation loss: 0.316661 Validation acc: 0.875000\n",
      "Epoch: 32/500 Iteration: 295 Train loss: 0.325394 Train acc: 0.876667\n",
      "Epoch: 33/500 Iteration: 300 Train loss: 0.390616 Train acc: 0.838333\n",
      "Epoch: 33/500 Iteration: 300 Validation loss: 0.310006 Validation acc: 0.880000\n",
      "Epoch: 33/500 Iteration: 305 Train loss: 0.329103 Train acc: 0.871667\n",
      "Epoch: 34/500 Iteration: 310 Train loss: 0.353357 Train acc: 0.851667\n",
      "Epoch: 34/500 Iteration: 310 Validation loss: 0.305479 Validation acc: 0.881667\n",
      "Epoch: 34/500 Iteration: 315 Train loss: 0.358266 Train acc: 0.856667\n",
      "Epoch: 35/500 Iteration: 320 Train loss: 0.348685 Train acc: 0.863333\n",
      "Epoch: 35/500 Iteration: 320 Validation loss: 0.303262 Validation acc: 0.885556\n",
      "Epoch: 36/500 Iteration: 325 Train loss: 0.314400 Train acc: 0.885000\n",
      "Epoch: 36/500 Iteration: 330 Train loss: 0.401717 Train acc: 0.850000\n",
      "Epoch: 36/500 Iteration: 330 Validation loss: 0.297333 Validation acc: 0.884444\n",
      "Epoch: 37/500 Iteration: 335 Train loss: 0.330112 Train acc: 0.868333\n",
      "Epoch: 37/500 Iteration: 340 Train loss: 0.302983 Train acc: 0.871667\n",
      "Epoch: 37/500 Iteration: 340 Validation loss: 0.295810 Validation acc: 0.886667\n",
      "Epoch: 38/500 Iteration: 345 Train loss: 0.348022 Train acc: 0.868333\n",
      "Epoch: 38/500 Iteration: 350 Train loss: 0.265842 Train acc: 0.896667\n",
      "Epoch: 38/500 Iteration: 350 Validation loss: 0.295125 Validation acc: 0.885556\n",
      "Epoch: 39/500 Iteration: 355 Train loss: 0.330362 Train acc: 0.868333\n",
      "Epoch: 39/500 Iteration: 360 Train loss: 0.297988 Train acc: 0.885000\n",
      "Epoch: 39/500 Iteration: 360 Validation loss: 0.291208 Validation acc: 0.888889\n",
      "Epoch: 40/500 Iteration: 365 Train loss: 0.294157 Train acc: 0.896667\n",
      "Epoch: 41/500 Iteration: 370 Train loss: 0.293318 Train acc: 0.878333\n",
      "Epoch: 41/500 Iteration: 370 Validation loss: 0.286099 Validation acc: 0.890000\n",
      "Epoch: 41/500 Iteration: 375 Train loss: 0.365624 Train acc: 0.868333\n",
      "Epoch: 42/500 Iteration: 380 Train loss: 0.289369 Train acc: 0.885000\n",
      "Epoch: 42/500 Iteration: 380 Validation loss: 0.283596 Validation acc: 0.891111\n",
      "Epoch: 42/500 Iteration: 385 Train loss: 0.299632 Train acc: 0.890000\n",
      "Epoch: 43/500 Iteration: 390 Train loss: 0.300481 Train acc: 0.890000\n",
      "Epoch: 43/500 Iteration: 390 Validation loss: 0.278231 Validation acc: 0.892778\n",
      "Epoch: 43/500 Iteration: 395 Train loss: 0.265219 Train acc: 0.906667\n",
      "Epoch: 44/500 Iteration: 400 Train loss: 0.280608 Train acc: 0.878333\n",
      "Epoch: 44/500 Iteration: 400 Validation loss: 0.273528 Validation acc: 0.893889\n",
      "Epoch: 44/500 Iteration: 405 Train loss: 0.299709 Train acc: 0.891667\n",
      "Epoch: 45/500 Iteration: 410 Train loss: 0.323049 Train acc: 0.873333\n",
      "Epoch: 45/500 Iteration: 410 Validation loss: 0.271345 Validation acc: 0.896111\n",
      "Epoch: 46/500 Iteration: 415 Train loss: 0.255747 Train acc: 0.891667\n",
      "Epoch: 46/500 Iteration: 420 Train loss: 0.341327 Train acc: 0.856667\n",
      "Epoch: 46/500 Iteration: 420 Validation loss: 0.269497 Validation acc: 0.898889\n",
      "Epoch: 47/500 Iteration: 425 Train loss: 0.260617 Train acc: 0.895000\n",
      "Epoch: 47/500 Iteration: 430 Train loss: 0.257595 Train acc: 0.901667\n",
      "Epoch: 47/500 Iteration: 430 Validation loss: 0.266805 Validation acc: 0.895000\n",
      "Epoch: 48/500 Iteration: 435 Train loss: 0.291983 Train acc: 0.890000\n",
      "Epoch: 48/500 Iteration: 440 Train loss: 0.241406 Train acc: 0.910000\n",
      "Epoch: 48/500 Iteration: 440 Validation loss: 0.264873 Validation acc: 0.897222\n",
      "Epoch: 49/500 Iteration: 445 Train loss: 0.242494 Train acc: 0.890000\n",
      "Epoch: 49/500 Iteration: 450 Train loss: 0.272736 Train acc: 0.898333\n",
      "Epoch: 49/500 Iteration: 450 Validation loss: 0.261155 Validation acc: 0.896667\n",
      "Epoch: 50/500 Iteration: 455 Train loss: 0.277731 Train acc: 0.881667\n",
      "Epoch: 51/500 Iteration: 460 Train loss: 0.235680 Train acc: 0.915000\n",
      "Epoch: 51/500 Iteration: 460 Validation loss: 0.260014 Validation acc: 0.896667\n",
      "Epoch: 51/500 Iteration: 465 Train loss: 0.302666 Train acc: 0.876667\n",
      "Epoch: 52/500 Iteration: 470 Train loss: 0.251658 Train acc: 0.893333\n",
      "Epoch: 52/500 Iteration: 470 Validation loss: 0.256547 Validation acc: 0.899444\n",
      "Epoch: 52/500 Iteration: 475 Train loss: 0.257446 Train acc: 0.901667\n",
      "Epoch: 53/500 Iteration: 480 Train loss: 0.273003 Train acc: 0.903333\n",
      "Epoch: 53/500 Iteration: 480 Validation loss: 0.254647 Validation acc: 0.900556\n",
      "Epoch: 53/500 Iteration: 485 Train loss: 0.262125 Train acc: 0.891667\n",
      "Epoch: 54/500 Iteration: 490 Train loss: 0.273008 Train acc: 0.890000\n",
      "Epoch: 54/500 Iteration: 490 Validation loss: 0.251868 Validation acc: 0.899444\n",
      "Epoch: 54/500 Iteration: 495 Train loss: 0.230385 Train acc: 0.918333\n",
      "Epoch: 55/500 Iteration: 500 Train loss: 0.259886 Train acc: 0.896667\n",
      "Epoch: 55/500 Iteration: 500 Validation loss: 0.248534 Validation acc: 0.903333\n",
      "Epoch: 56/500 Iteration: 505 Train loss: 0.241859 Train acc: 0.895000\n",
      "Epoch: 56/500 Iteration: 510 Train loss: 0.288462 Train acc: 0.888333\n",
      "Epoch: 56/500 Iteration: 510 Validation loss: 0.249333 Validation acc: 0.901667\n",
      "Epoch: 57/500 Iteration: 515 Train loss: 0.252637 Train acc: 0.910000\n",
      "Epoch: 57/500 Iteration: 520 Train loss: 0.258713 Train acc: 0.891667\n",
      "Epoch: 57/500 Iteration: 520 Validation loss: 0.248466 Validation acc: 0.903333\n",
      "Epoch: 58/500 Iteration: 525 Train loss: 0.251105 Train acc: 0.900000\n",
      "Epoch: 58/500 Iteration: 530 Train loss: 0.244942 Train acc: 0.896667\n",
      "Epoch: 58/500 Iteration: 530 Validation loss: 0.250645 Validation acc: 0.905000\n",
      "Epoch: 59/500 Iteration: 535 Train loss: 0.223370 Train acc: 0.920000\n",
      "Epoch: 59/500 Iteration: 540 Train loss: 0.242725 Train acc: 0.913333\n",
      "Epoch: 59/500 Iteration: 540 Validation loss: 0.245995 Validation acc: 0.903889\n",
      "Epoch: 60/500 Iteration: 545 Train loss: 0.249229 Train acc: 0.910000\n",
      "Epoch: 61/500 Iteration: 550 Train loss: 0.224263 Train acc: 0.910000\n",
      "Epoch: 61/500 Iteration: 550 Validation loss: 0.242384 Validation acc: 0.905000\n",
      "Epoch: 61/500 Iteration: 555 Train loss: 0.284605 Train acc: 0.891667\n",
      "Epoch: 62/500 Iteration: 560 Train loss: 0.231079 Train acc: 0.920000\n",
      "Epoch: 62/500 Iteration: 560 Validation loss: 0.239525 Validation acc: 0.906111\n",
      "Epoch: 62/500 Iteration: 565 Train loss: 0.240494 Train acc: 0.905000\n",
      "Epoch: 63/500 Iteration: 570 Train loss: 0.217681 Train acc: 0.923333\n",
      "Epoch: 63/500 Iteration: 570 Validation loss: 0.236325 Validation acc: 0.905000\n",
      "Epoch: 63/500 Iteration: 575 Train loss: 0.245088 Train acc: 0.893333\n",
      "Epoch: 64/500 Iteration: 580 Train loss: 0.231868 Train acc: 0.906667\n",
      "Epoch: 64/500 Iteration: 580 Validation loss: 0.234503 Validation acc: 0.906111\n",
      "Epoch: 64/500 Iteration: 585 Train loss: 0.229412 Train acc: 0.905000\n",
      "Epoch: 65/500 Iteration: 590 Train loss: 0.228623 Train acc: 0.921667\n",
      "Epoch: 65/500 Iteration: 590 Validation loss: 0.236307 Validation acc: 0.904444\n",
      "Epoch: 66/500 Iteration: 595 Train loss: 0.224117 Train acc: 0.918333\n",
      "Epoch: 66/500 Iteration: 600 Train loss: 0.278245 Train acc: 0.885000\n",
      "Epoch: 66/500 Iteration: 600 Validation loss: 0.236849 Validation acc: 0.905556\n",
      "Epoch: 67/500 Iteration: 605 Train loss: 0.218038 Train acc: 0.906667\n",
      "Epoch: 67/500 Iteration: 610 Train loss: 0.246494 Train acc: 0.906667\n",
      "Epoch: 67/500 Iteration: 610 Validation loss: 0.234011 Validation acc: 0.909444\n",
      "Epoch: 68/500 Iteration: 615 Train loss: 0.238293 Train acc: 0.908333\n",
      "Epoch: 68/500 Iteration: 620 Train loss: 0.206752 Train acc: 0.915000\n",
      "Epoch: 68/500 Iteration: 620 Validation loss: 0.232216 Validation acc: 0.910556\n",
      "Epoch: 69/500 Iteration: 625 Train loss: 0.224226 Train acc: 0.910000\n",
      "Epoch: 69/500 Iteration: 630 Train loss: 0.213213 Train acc: 0.911667\n",
      "Epoch: 69/500 Iteration: 630 Validation loss: 0.231232 Validation acc: 0.909444\n",
      "Epoch: 70/500 Iteration: 635 Train loss: 0.224672 Train acc: 0.916667\n",
      "Epoch: 71/500 Iteration: 640 Train loss: 0.201112 Train acc: 0.933333\n",
      "Epoch: 71/500 Iteration: 640 Validation loss: 0.229394 Validation acc: 0.910000\n",
      "Epoch: 71/500 Iteration: 645 Train loss: 0.266897 Train acc: 0.890000\n",
      "Epoch: 72/500 Iteration: 650 Train loss: 0.212978 Train acc: 0.921667\n",
      "Epoch: 72/500 Iteration: 650 Validation loss: 0.230191 Validation acc: 0.912222\n",
      "Epoch: 72/500 Iteration: 655 Train loss: 0.185444 Train acc: 0.931667\n",
      "Epoch: 73/500 Iteration: 660 Train loss: 0.204283 Train acc: 0.920000\n",
      "Epoch: 73/500 Iteration: 660 Validation loss: 0.228492 Validation acc: 0.910000\n",
      "Epoch: 73/500 Iteration: 665 Train loss: 0.212308 Train acc: 0.906667\n",
      "Epoch: 74/500 Iteration: 670 Train loss: 0.188288 Train acc: 0.926667\n",
      "Epoch: 74/500 Iteration: 670 Validation loss: 0.227478 Validation acc: 0.909444\n",
      "Epoch: 74/500 Iteration: 675 Train loss: 0.217120 Train acc: 0.915000\n",
      "Epoch: 75/500 Iteration: 680 Train loss: 0.236057 Train acc: 0.901667\n",
      "Epoch: 75/500 Iteration: 680 Validation loss: 0.225259 Validation acc: 0.908889\n",
      "Epoch: 76/500 Iteration: 685 Train loss: 0.177920 Train acc: 0.941667\n",
      "Epoch: 76/500 Iteration: 690 Train loss: 0.243770 Train acc: 0.918333\n",
      "Epoch: 76/500 Iteration: 690 Validation loss: 0.224936 Validation acc: 0.911111\n",
      "Epoch: 77/500 Iteration: 695 Train loss: 0.175388 Train acc: 0.935000\n",
      "Epoch: 77/500 Iteration: 700 Train loss: 0.206282 Train acc: 0.923333\n",
      "Epoch: 77/500 Iteration: 700 Validation loss: 0.226042 Validation acc: 0.911667\n",
      "Epoch: 78/500 Iteration: 705 Train loss: 0.186065 Train acc: 0.940000\n",
      "Epoch: 78/500 Iteration: 710 Train loss: 0.192643 Train acc: 0.938333\n",
      "Epoch: 78/500 Iteration: 710 Validation loss: 0.226406 Validation acc: 0.910000\n",
      "Epoch: 79/500 Iteration: 715 Train loss: 0.188158 Train acc: 0.928333\n",
      "Epoch: 79/500 Iteration: 720 Train loss: 0.202471 Train acc: 0.938333\n",
      "Epoch: 79/500 Iteration: 720 Validation loss: 0.226927 Validation acc: 0.909444\n",
      "Epoch: 80/500 Iteration: 725 Train loss: 0.223817 Train acc: 0.913333\n",
      "Epoch: 81/500 Iteration: 730 Train loss: 0.174817 Train acc: 0.935000\n",
      "Epoch: 81/500 Iteration: 730 Validation loss: 0.221338 Validation acc: 0.912778\n",
      "Epoch: 81/500 Iteration: 735 Train loss: 0.223059 Train acc: 0.908333\n",
      "Epoch: 82/500 Iteration: 740 Train loss: 0.183718 Train acc: 0.931667\n",
      "Epoch: 82/500 Iteration: 740 Validation loss: 0.220623 Validation acc: 0.912222\n",
      "Epoch: 82/500 Iteration: 745 Train loss: 0.200347 Train acc: 0.931667\n",
      "Epoch: 83/500 Iteration: 750 Train loss: 0.191867 Train acc: 0.923333\n",
      "Epoch: 83/500 Iteration: 750 Validation loss: 0.217862 Validation acc: 0.911667\n",
      "Epoch: 83/500 Iteration: 755 Train loss: 0.166000 Train acc: 0.936667\n",
      "Epoch: 84/500 Iteration: 760 Train loss: 0.195631 Train acc: 0.935000\n",
      "Epoch: 84/500 Iteration: 760 Validation loss: 0.215640 Validation acc: 0.912222\n",
      "Epoch: 84/500 Iteration: 765 Train loss: 0.177874 Train acc: 0.931667\n",
      "Epoch: 85/500 Iteration: 770 Train loss: 0.183476 Train acc: 0.933333\n",
      "Epoch: 85/500 Iteration: 770 Validation loss: 0.215582 Validation acc: 0.912222\n",
      "Epoch: 86/500 Iteration: 775 Train loss: 0.166774 Train acc: 0.943333\n",
      "Epoch: 86/500 Iteration: 780 Train loss: 0.241148 Train acc: 0.908333\n",
      "Epoch: 86/500 Iteration: 780 Validation loss: 0.219869 Validation acc: 0.912222\n",
      "Epoch: 87/500 Iteration: 785 Train loss: 0.182118 Train acc: 0.931667\n",
      "Epoch: 87/500 Iteration: 790 Train loss: 0.182487 Train acc: 0.938333\n",
      "Epoch: 87/500 Iteration: 790 Validation loss: 0.221128 Validation acc: 0.910000\n",
      "Epoch: 88/500 Iteration: 795 Train loss: 0.176484 Train acc: 0.933333\n",
      "Epoch: 88/500 Iteration: 800 Train loss: 0.167718 Train acc: 0.933333\n",
      "Epoch: 88/500 Iteration: 800 Validation loss: 0.225195 Validation acc: 0.910556\n",
      "Epoch: 89/500 Iteration: 805 Train loss: 0.147684 Train acc: 0.960000\n",
      "Epoch: 89/500 Iteration: 810 Train loss: 0.156543 Train acc: 0.948333\n",
      "Epoch: 89/500 Iteration: 810 Validation loss: 0.218096 Validation acc: 0.912778\n",
      "Epoch: 90/500 Iteration: 815 Train loss: 0.196922 Train acc: 0.926667\n",
      "Epoch: 91/500 Iteration: 820 Train loss: 0.165151 Train acc: 0.935000\n",
      "Epoch: 91/500 Iteration: 820 Validation loss: 0.216804 Validation acc: 0.913889\n",
      "Epoch: 91/500 Iteration: 825 Train loss: 0.198650 Train acc: 0.925000\n",
      "Epoch: 92/500 Iteration: 830 Train loss: 0.143208 Train acc: 0.950000\n",
      "Epoch: 92/500 Iteration: 830 Validation loss: 0.213424 Validation acc: 0.914444\n",
      "Epoch: 92/500 Iteration: 835 Train loss: 0.175750 Train acc: 0.940000\n",
      "Epoch: 93/500 Iteration: 840 Train loss: 0.164008 Train acc: 0.936667\n",
      "Epoch: 93/500 Iteration: 840 Validation loss: 0.212145 Validation acc: 0.916667\n",
      "Epoch: 93/500 Iteration: 845 Train loss: 0.179241 Train acc: 0.933333\n",
      "Epoch: 94/500 Iteration: 850 Train loss: 0.160392 Train acc: 0.946667\n",
      "Epoch: 94/500 Iteration: 850 Validation loss: 0.209958 Validation acc: 0.916111\n",
      "Epoch: 94/500 Iteration: 855 Train loss: 0.151459 Train acc: 0.943333\n",
      "Epoch: 95/500 Iteration: 860 Train loss: 0.182037 Train acc: 0.928333\n",
      "Epoch: 95/500 Iteration: 860 Validation loss: 0.210139 Validation acc: 0.914444\n",
      "Epoch: 96/500 Iteration: 865 Train loss: 0.151009 Train acc: 0.941667\n",
      "Epoch: 96/500 Iteration: 870 Train loss: 0.191024 Train acc: 0.933333\n",
      "Epoch: 96/500 Iteration: 870 Validation loss: 0.214402 Validation acc: 0.916667\n",
      "Epoch: 97/500 Iteration: 875 Train loss: 0.139477 Train acc: 0.946667\n",
      "Epoch: 97/500 Iteration: 880 Train loss: 0.164311 Train acc: 0.941667\n",
      "Epoch: 97/500 Iteration: 880 Validation loss: 0.216571 Validation acc: 0.913333\n",
      "Epoch: 98/500 Iteration: 885 Train loss: 0.162691 Train acc: 0.938333\n",
      "Epoch: 98/500 Iteration: 890 Train loss: 0.157338 Train acc: 0.928333\n",
      "Epoch: 98/500 Iteration: 890 Validation loss: 0.220818 Validation acc: 0.910556\n",
      "Epoch: 99/500 Iteration: 895 Train loss: 0.151956 Train acc: 0.946667\n",
      "Epoch: 99/500 Iteration: 900 Train loss: 0.164293 Train acc: 0.938333\n",
      "Epoch: 99/500 Iteration: 900 Validation loss: 0.214984 Validation acc: 0.914444\n",
      "Epoch: 100/500 Iteration: 905 Train loss: 0.177597 Train acc: 0.938333\n",
      "Epoch: 101/500 Iteration: 910 Train loss: 0.158834 Train acc: 0.945000\n",
      "Epoch: 101/500 Iteration: 910 Validation loss: 0.209617 Validation acc: 0.915555\n",
      "Epoch: 101/500 Iteration: 915 Train loss: 0.171489 Train acc: 0.938333\n",
      "Epoch: 102/500 Iteration: 920 Train loss: 0.166986 Train acc: 0.941667\n",
      "Epoch: 102/500 Iteration: 920 Validation loss: 0.208045 Validation acc: 0.916667\n",
      "Epoch: 102/500 Iteration: 925 Train loss: 0.149563 Train acc: 0.943333\n",
      "Epoch: 103/500 Iteration: 930 Train loss: 0.144496 Train acc: 0.946667\n",
      "Epoch: 103/500 Iteration: 930 Validation loss: 0.208684 Validation acc: 0.915555\n",
      "Epoch: 103/500 Iteration: 935 Train loss: 0.150924 Train acc: 0.950000\n",
      "Epoch: 104/500 Iteration: 940 Train loss: 0.150765 Train acc: 0.945000\n",
      "Epoch: 104/500 Iteration: 940 Validation loss: 0.208207 Validation acc: 0.914444\n",
      "Epoch: 104/500 Iteration: 945 Train loss: 0.151696 Train acc: 0.943333\n",
      "Epoch: 105/500 Iteration: 950 Train loss: 0.160380 Train acc: 0.933333\n",
      "Epoch: 105/500 Iteration: 950 Validation loss: 0.206796 Validation acc: 0.917778\n",
      "Epoch: 106/500 Iteration: 955 Train loss: 0.151103 Train acc: 0.943333\n",
      "Epoch: 106/500 Iteration: 960 Train loss: 0.212005 Train acc: 0.920000\n",
      "Epoch: 106/500 Iteration: 960 Validation loss: 0.207190 Validation acc: 0.916667\n",
      "Epoch: 107/500 Iteration: 965 Train loss: 0.127910 Train acc: 0.958333\n",
      "Epoch: 107/500 Iteration: 970 Train loss: 0.159545 Train acc: 0.935000\n",
      "Epoch: 107/500 Iteration: 970 Validation loss: 0.209779 Validation acc: 0.918889\n",
      "Epoch: 108/500 Iteration: 975 Train loss: 0.164426 Train acc: 0.940000\n",
      "Epoch: 108/500 Iteration: 980 Train loss: 0.135806 Train acc: 0.951667\n",
      "Epoch: 108/500 Iteration: 980 Validation loss: 0.213215 Validation acc: 0.915555\n",
      "Epoch: 109/500 Iteration: 985 Train loss: 0.124922 Train acc: 0.956667\n",
      "Epoch: 109/500 Iteration: 990 Train loss: 0.149589 Train acc: 0.941667\n",
      "Epoch: 109/500 Iteration: 990 Validation loss: 0.206725 Validation acc: 0.917778\n",
      "Epoch: 110/500 Iteration: 995 Train loss: 0.164950 Train acc: 0.933333\n",
      "Epoch: 111/500 Iteration: 1000 Train loss: 0.139340 Train acc: 0.943333\n",
      "Epoch: 111/500 Iteration: 1000 Validation loss: 0.208738 Validation acc: 0.921111\n",
      "Epoch: 111/500 Iteration: 1005 Train loss: 0.191843 Train acc: 0.926667\n",
      "Epoch: 112/500 Iteration: 1010 Train loss: 0.127211 Train acc: 0.943333\n",
      "Epoch: 112/500 Iteration: 1010 Validation loss: 0.210946 Validation acc: 0.918333\n",
      "Epoch: 112/500 Iteration: 1015 Train loss: 0.168049 Train acc: 0.941667\n",
      "Epoch: 113/500 Iteration: 1020 Train loss: 0.153027 Train acc: 0.951667\n",
      "Epoch: 113/500 Iteration: 1020 Validation loss: 0.207543 Validation acc: 0.920000\n",
      "Epoch: 113/500 Iteration: 1025 Train loss: 0.134493 Train acc: 0.945000\n",
      "Epoch: 114/500 Iteration: 1030 Train loss: 0.144740 Train acc: 0.946667\n",
      "Epoch: 114/500 Iteration: 1030 Validation loss: 0.204068 Validation acc: 0.921111\n",
      "Epoch: 114/500 Iteration: 1035 Train loss: 0.125343 Train acc: 0.965000\n",
      "Epoch: 115/500 Iteration: 1040 Train loss: 0.126233 Train acc: 0.958333\n",
      "Epoch: 115/500 Iteration: 1040 Validation loss: 0.206792 Validation acc: 0.920000\n",
      "Epoch: 116/500 Iteration: 1045 Train loss: 0.126108 Train acc: 0.956667\n",
      "Epoch: 116/500 Iteration: 1050 Train loss: 0.194354 Train acc: 0.930000\n",
      "Epoch: 116/500 Iteration: 1050 Validation loss: 0.205884 Validation acc: 0.918889\n",
      "Epoch: 117/500 Iteration: 1055 Train loss: 0.151813 Train acc: 0.951667\n",
      "Epoch: 117/500 Iteration: 1060 Train loss: 0.129081 Train acc: 0.963333\n",
      "Epoch: 117/500 Iteration: 1060 Validation loss: 0.203615 Validation acc: 0.919444\n",
      "Epoch: 118/500 Iteration: 1065 Train loss: 0.138982 Train acc: 0.950000\n",
      "Epoch: 118/500 Iteration: 1070 Train loss: 0.158994 Train acc: 0.926667\n",
      "Epoch: 118/500 Iteration: 1070 Validation loss: 0.203357 Validation acc: 0.921111\n",
      "Epoch: 119/500 Iteration: 1075 Train loss: 0.137636 Train acc: 0.950000\n",
      "Epoch: 119/500 Iteration: 1080 Train loss: 0.116245 Train acc: 0.963333\n",
      "Epoch: 119/500 Iteration: 1080 Validation loss: 0.202324 Validation acc: 0.921667\n",
      "Epoch: 120/500 Iteration: 1085 Train loss: 0.138769 Train acc: 0.936667\n",
      "Epoch: 121/500 Iteration: 1090 Train loss: 0.127675 Train acc: 0.951667\n",
      "Epoch: 121/500 Iteration: 1090 Validation loss: 0.203614 Validation acc: 0.925000\n",
      "Epoch: 121/500 Iteration: 1095 Train loss: 0.168627 Train acc: 0.943333\n",
      "Epoch: 122/500 Iteration: 1100 Train loss: 0.131805 Train acc: 0.945000\n",
      "Epoch: 122/500 Iteration: 1100 Validation loss: 0.206671 Validation acc: 0.921667\n",
      "Epoch: 122/500 Iteration: 1105 Train loss: 0.149519 Train acc: 0.938333\n",
      "Epoch: 123/500 Iteration: 1110 Train loss: 0.149754 Train acc: 0.945000\n",
      "Epoch: 123/500 Iteration: 1110 Validation loss: 0.207150 Validation acc: 0.921111\n",
      "Epoch: 123/500 Iteration: 1115 Train loss: 0.123450 Train acc: 0.956667\n",
      "Epoch: 124/500 Iteration: 1120 Train loss: 0.120714 Train acc: 0.965000\n",
      "Epoch: 124/500 Iteration: 1120 Validation loss: 0.202404 Validation acc: 0.923889\n",
      "Epoch: 124/500 Iteration: 1125 Train loss: 0.126829 Train acc: 0.953333\n",
      "Epoch: 125/500 Iteration: 1130 Train loss: 0.148030 Train acc: 0.946667\n",
      "Epoch: 125/500 Iteration: 1130 Validation loss: 0.202960 Validation acc: 0.923333\n",
      "Epoch: 126/500 Iteration: 1135 Train loss: 0.139651 Train acc: 0.940000\n",
      "Epoch: 126/500 Iteration: 1140 Train loss: 0.175347 Train acc: 0.931667\n",
      "Epoch: 126/500 Iteration: 1140 Validation loss: 0.214081 Validation acc: 0.918889\n",
      "Epoch: 127/500 Iteration: 1145 Train loss: 0.131620 Train acc: 0.941667\n",
      "Epoch: 127/500 Iteration: 1150 Train loss: 0.137413 Train acc: 0.945000\n",
      "Epoch: 127/500 Iteration: 1150 Validation loss: 0.211244 Validation acc: 0.919444\n",
      "Epoch: 128/500 Iteration: 1155 Train loss: 0.129154 Train acc: 0.945000\n",
      "Epoch: 128/500 Iteration: 1160 Train loss: 0.126404 Train acc: 0.950000\n",
      "Epoch: 128/500 Iteration: 1160 Validation loss: 0.208551 Validation acc: 0.920556\n",
      "Epoch: 129/500 Iteration: 1165 Train loss: 0.142129 Train acc: 0.940000\n",
      "Epoch: 129/500 Iteration: 1170 Train loss: 0.131663 Train acc: 0.951667\n",
      "Epoch: 129/500 Iteration: 1170 Validation loss: 0.205795 Validation acc: 0.922222\n",
      "Epoch: 130/500 Iteration: 1175 Train loss: 0.160899 Train acc: 0.933333\n",
      "Epoch: 131/500 Iteration: 1180 Train loss: 0.117371 Train acc: 0.963333\n",
      "Epoch: 131/500 Iteration: 1180 Validation loss: 0.201893 Validation acc: 0.925000\n",
      "Epoch: 131/500 Iteration: 1185 Train loss: 0.197046 Train acc: 0.935000\n",
      "Epoch: 132/500 Iteration: 1190 Train loss: 0.136672 Train acc: 0.951667\n",
      "Epoch: 132/500 Iteration: 1190 Validation loss: 0.208307 Validation acc: 0.922778\n",
      "Epoch: 132/500 Iteration: 1195 Train loss: 0.133755 Train acc: 0.953333\n",
      "Epoch: 133/500 Iteration: 1200 Train loss: 0.145845 Train acc: 0.938333\n",
      "Epoch: 133/500 Iteration: 1200 Validation loss: 0.204009 Validation acc: 0.922222\n",
      "Epoch: 133/500 Iteration: 1205 Train loss: 0.114765 Train acc: 0.960000\n",
      "Epoch: 134/500 Iteration: 1210 Train loss: 0.127827 Train acc: 0.955000\n",
      "Epoch: 134/500 Iteration: 1210 Validation loss: 0.201640 Validation acc: 0.924444\n",
      "Epoch: 134/500 Iteration: 1215 Train loss: 0.113470 Train acc: 0.965000\n",
      "Epoch: 135/500 Iteration: 1220 Train loss: 0.125883 Train acc: 0.956667\n",
      "Epoch: 135/500 Iteration: 1220 Validation loss: 0.201715 Validation acc: 0.924444\n",
      "Epoch: 136/500 Iteration: 1225 Train loss: 0.134857 Train acc: 0.950000\n",
      "Epoch: 136/500 Iteration: 1230 Train loss: 0.156439 Train acc: 0.946667\n",
      "Epoch: 136/500 Iteration: 1230 Validation loss: 0.203075 Validation acc: 0.922222\n",
      "Epoch: 137/500 Iteration: 1235 Train loss: 0.126009 Train acc: 0.956667\n",
      "Epoch: 137/500 Iteration: 1240 Train loss: 0.140479 Train acc: 0.951667\n",
      "Epoch: 137/500 Iteration: 1240 Validation loss: 0.205316 Validation acc: 0.924444\n",
      "Epoch: 138/500 Iteration: 1245 Train loss: 0.135464 Train acc: 0.945000\n",
      "Epoch: 138/500 Iteration: 1250 Train loss: 0.119260 Train acc: 0.950000\n",
      "Epoch: 138/500 Iteration: 1250 Validation loss: 0.200923 Validation acc: 0.923333\n",
      "Epoch: 139/500 Iteration: 1255 Train loss: 0.117060 Train acc: 0.963333\n",
      "Epoch: 139/500 Iteration: 1260 Train loss: 0.126792 Train acc: 0.960000\n",
      "Epoch: 139/500 Iteration: 1260 Validation loss: 0.197263 Validation acc: 0.927222\n",
      "Epoch: 140/500 Iteration: 1265 Train loss: 0.131971 Train acc: 0.955000\n",
      "Epoch: 141/500 Iteration: 1270 Train loss: 0.117609 Train acc: 0.946667\n",
      "Epoch: 141/500 Iteration: 1270 Validation loss: 0.201886 Validation acc: 0.925000\n",
      "Epoch: 141/500 Iteration: 1275 Train loss: 0.145312 Train acc: 0.948333\n",
      "Epoch: 142/500 Iteration: 1280 Train loss: 0.114844 Train acc: 0.966667\n",
      "Epoch: 142/500 Iteration: 1280 Validation loss: 0.199197 Validation acc: 0.927222\n",
      "Epoch: 142/500 Iteration: 1285 Train loss: 0.131447 Train acc: 0.955000\n",
      "Epoch: 143/500 Iteration: 1290 Train loss: 0.124362 Train acc: 0.956667\n",
      "Epoch: 143/500 Iteration: 1290 Validation loss: 0.205018 Validation acc: 0.925000\n",
      "Epoch: 143/500 Iteration: 1295 Train loss: 0.135724 Train acc: 0.958333\n",
      "Epoch: 144/500 Iteration: 1300 Train loss: 0.123207 Train acc: 0.955000\n",
      "Epoch: 144/500 Iteration: 1300 Validation loss: 0.199840 Validation acc: 0.929444\n",
      "Epoch: 144/500 Iteration: 1305 Train loss: 0.113964 Train acc: 0.958333\n",
      "Epoch: 145/500 Iteration: 1310 Train loss: 0.127091 Train acc: 0.953333\n",
      "Epoch: 145/500 Iteration: 1310 Validation loss: 0.200947 Validation acc: 0.926667\n",
      "Epoch: 146/500 Iteration: 1315 Train loss: 0.106556 Train acc: 0.960000\n",
      "Epoch: 146/500 Iteration: 1320 Train loss: 0.137292 Train acc: 0.948333\n",
      "Epoch: 146/500 Iteration: 1320 Validation loss: 0.206321 Validation acc: 0.927222\n",
      "Epoch: 147/500 Iteration: 1325 Train loss: 0.112675 Train acc: 0.958333\n",
      "Epoch: 147/500 Iteration: 1330 Train loss: 0.117824 Train acc: 0.946667\n",
      "Epoch: 147/500 Iteration: 1330 Validation loss: 0.206251 Validation acc: 0.923333\n",
      "Epoch: 148/500 Iteration: 1335 Train loss: 0.124016 Train acc: 0.948333\n",
      "Epoch: 148/500 Iteration: 1340 Train loss: 0.119743 Train acc: 0.953333\n",
      "Epoch: 148/500 Iteration: 1340 Validation loss: 0.209482 Validation acc: 0.923333\n",
      "Epoch: 149/500 Iteration: 1345 Train loss: 0.109653 Train acc: 0.963333\n",
      "Epoch: 149/500 Iteration: 1350 Train loss: 0.120899 Train acc: 0.950000\n",
      "Epoch: 149/500 Iteration: 1350 Validation loss: 0.213127 Validation acc: 0.923333\n",
      "Epoch: 150/500 Iteration: 1355 Train loss: 0.108689 Train acc: 0.963333\n",
      "Epoch: 151/500 Iteration: 1360 Train loss: 0.105422 Train acc: 0.963333\n",
      "Epoch: 151/500 Iteration: 1360 Validation loss: 0.204251 Validation acc: 0.926667\n",
      "Epoch: 151/500 Iteration: 1365 Train loss: 0.121266 Train acc: 0.960000\n",
      "Epoch: 152/500 Iteration: 1370 Train loss: 0.098689 Train acc: 0.965000\n",
      "Epoch: 152/500 Iteration: 1370 Validation loss: 0.199535 Validation acc: 0.930000\n",
      "Epoch: 152/500 Iteration: 1375 Train loss: 0.095236 Train acc: 0.975000\n",
      "Epoch: 153/500 Iteration: 1380 Train loss: 0.105784 Train acc: 0.963333\n",
      "Epoch: 153/500 Iteration: 1380 Validation loss: 0.198244 Validation acc: 0.928333\n",
      "Epoch: 153/500 Iteration: 1385 Train loss: 0.103521 Train acc: 0.965000\n",
      "Epoch: 154/500 Iteration: 1390 Train loss: 0.107712 Train acc: 0.960000\n",
      "Epoch: 154/500 Iteration: 1390 Validation loss: 0.199016 Validation acc: 0.929444\n",
      "Epoch: 154/500 Iteration: 1395 Train loss: 0.099395 Train acc: 0.966667\n",
      "Epoch: 155/500 Iteration: 1400 Train loss: 0.125455 Train acc: 0.948333\n",
      "Epoch: 155/500 Iteration: 1400 Validation loss: 0.197710 Validation acc: 0.931111\n",
      "Epoch: 156/500 Iteration: 1405 Train loss: 0.094124 Train acc: 0.963333\n",
      "Epoch: 156/500 Iteration: 1410 Train loss: 0.114213 Train acc: 0.956667\n",
      "Epoch: 156/500 Iteration: 1410 Validation loss: 0.199851 Validation acc: 0.930556\n",
      "Epoch: 157/500 Iteration: 1415 Train loss: 0.134818 Train acc: 0.951667\n",
      "Epoch: 157/500 Iteration: 1420 Train loss: 0.121268 Train acc: 0.951667\n",
      "Epoch: 157/500 Iteration: 1420 Validation loss: 0.201163 Validation acc: 0.931111\n",
      "Epoch: 158/500 Iteration: 1425 Train loss: 0.110233 Train acc: 0.966667\n",
      "Epoch: 158/500 Iteration: 1430 Train loss: 0.089050 Train acc: 0.971667\n",
      "Epoch: 158/500 Iteration: 1430 Validation loss: 0.204257 Validation acc: 0.931111\n",
      "Epoch: 159/500 Iteration: 1435 Train loss: 0.113844 Train acc: 0.955000\n",
      "Epoch: 159/500 Iteration: 1440 Train loss: 0.108677 Train acc: 0.955000\n",
      "Epoch: 159/500 Iteration: 1440 Validation loss: 0.207207 Validation acc: 0.930000\n",
      "Epoch: 160/500 Iteration: 1445 Train loss: 0.132009 Train acc: 0.936667\n",
      "Epoch: 161/500 Iteration: 1450 Train loss: 0.119046 Train acc: 0.948333\n",
      "Epoch: 161/500 Iteration: 1450 Validation loss: 0.201878 Validation acc: 0.929444\n",
      "Epoch: 161/500 Iteration: 1455 Train loss: 0.116976 Train acc: 0.966667\n",
      "Epoch: 162/500 Iteration: 1460 Train loss: 0.120080 Train acc: 0.965000\n",
      "Epoch: 162/500 Iteration: 1460 Validation loss: 0.199150 Validation acc: 0.928889\n",
      "Epoch: 162/500 Iteration: 1465 Train loss: 0.101555 Train acc: 0.963333\n",
      "Epoch: 163/500 Iteration: 1470 Train loss: 0.100361 Train acc: 0.960000\n",
      "Epoch: 163/500 Iteration: 1470 Validation loss: 0.199034 Validation acc: 0.929444\n",
      "Epoch: 163/500 Iteration: 1475 Train loss: 0.097259 Train acc: 0.966667\n",
      "Epoch: 164/500 Iteration: 1480 Train loss: 0.111694 Train acc: 0.961667\n",
      "Epoch: 164/500 Iteration: 1480 Validation loss: 0.200741 Validation acc: 0.931111\n",
      "Epoch: 164/500 Iteration: 1485 Train loss: 0.088831 Train acc: 0.968333\n",
      "Epoch: 165/500 Iteration: 1490 Train loss: 0.103468 Train acc: 0.965000\n",
      "Epoch: 165/500 Iteration: 1490 Validation loss: 0.205436 Validation acc: 0.927778\n",
      "Epoch: 166/500 Iteration: 1495 Train loss: 0.108883 Train acc: 0.958333\n",
      "Epoch: 166/500 Iteration: 1500 Train loss: 0.142833 Train acc: 0.951667\n",
      "Epoch: 166/500 Iteration: 1500 Validation loss: 0.201707 Validation acc: 0.929444\n",
      "Epoch: 167/500 Iteration: 1505 Train loss: 0.092517 Train acc: 0.965000\n",
      "Epoch: 167/500 Iteration: 1510 Train loss: 0.101811 Train acc: 0.965000\n",
      "Epoch: 167/500 Iteration: 1510 Validation loss: 0.199778 Validation acc: 0.926111\n",
      "Epoch: 168/500 Iteration: 1515 Train loss: 0.105986 Train acc: 0.965000\n",
      "Epoch: 168/500 Iteration: 1520 Train loss: 0.115326 Train acc: 0.950000\n",
      "Epoch: 168/500 Iteration: 1520 Validation loss: 0.198129 Validation acc: 0.927778\n",
      "Epoch: 169/500 Iteration: 1525 Train loss: 0.089479 Train acc: 0.966667\n",
      "Epoch: 169/500 Iteration: 1530 Train loss: 0.096990 Train acc: 0.975000\n",
      "Epoch: 169/500 Iteration: 1530 Validation loss: 0.200992 Validation acc: 0.929444\n",
      "Epoch: 170/500 Iteration: 1535 Train loss: 0.079189 Train acc: 0.973333\n",
      "Epoch: 171/500 Iteration: 1540 Train loss: 0.080457 Train acc: 0.968333\n",
      "Epoch: 171/500 Iteration: 1540 Validation loss: 0.198486 Validation acc: 0.933333\n",
      "Epoch: 171/500 Iteration: 1545 Train loss: 0.123580 Train acc: 0.955000\n",
      "Epoch: 172/500 Iteration: 1550 Train loss: 0.092305 Train acc: 0.970000\n",
      "Epoch: 172/500 Iteration: 1550 Validation loss: 0.197339 Validation acc: 0.933889\n",
      "Epoch: 172/500 Iteration: 1555 Train loss: 0.103094 Train acc: 0.968333\n",
      "Epoch: 173/500 Iteration: 1560 Train loss: 0.086191 Train acc: 0.976667\n",
      "Epoch: 173/500 Iteration: 1560 Validation loss: 0.201891 Validation acc: 0.926667\n",
      "Epoch: 173/500 Iteration: 1565 Train loss: 0.092011 Train acc: 0.968333\n",
      "Epoch: 174/500 Iteration: 1570 Train loss: 0.089201 Train acc: 0.966667\n",
      "Epoch: 174/500 Iteration: 1570 Validation loss: 0.200141 Validation acc: 0.928889\n",
      "Epoch: 174/500 Iteration: 1575 Train loss: 0.097135 Train acc: 0.966667\n",
      "Epoch: 175/500 Iteration: 1580 Train loss: 0.107350 Train acc: 0.956667\n",
      "Epoch: 175/500 Iteration: 1580 Validation loss: 0.198848 Validation acc: 0.928889\n",
      "Epoch: 176/500 Iteration: 1585 Train loss: 0.074685 Train acc: 0.980000\n",
      "Epoch: 176/500 Iteration: 1590 Train loss: 0.113281 Train acc: 0.961667\n",
      "Epoch: 176/500 Iteration: 1590 Validation loss: 0.206024 Validation acc: 0.927778\n",
      "Epoch: 177/500 Iteration: 1595 Train loss: 0.091162 Train acc: 0.965000\n",
      "Epoch: 177/500 Iteration: 1600 Train loss: 0.122780 Train acc: 0.953333\n",
      "Epoch: 177/500 Iteration: 1600 Validation loss: 0.207851 Validation acc: 0.927778\n",
      "Epoch: 178/500 Iteration: 1605 Train loss: 0.112514 Train acc: 0.956667\n",
      "Epoch: 178/500 Iteration: 1610 Train loss: 0.108893 Train acc: 0.951667\n",
      "Epoch: 178/500 Iteration: 1610 Validation loss: 0.206822 Validation acc: 0.930556\n",
      "Epoch: 179/500 Iteration: 1615 Train loss: 0.112584 Train acc: 0.960000\n",
      "Epoch: 179/500 Iteration: 1620 Train loss: 0.086272 Train acc: 0.970000\n",
      "Epoch: 179/500 Iteration: 1620 Validation loss: 0.201609 Validation acc: 0.931111\n",
      "Epoch: 180/500 Iteration: 1625 Train loss: 0.101069 Train acc: 0.953333\n",
      "Epoch: 181/500 Iteration: 1630 Train loss: 0.101145 Train acc: 0.966667\n",
      "Epoch: 181/500 Iteration: 1630 Validation loss: 0.204494 Validation acc: 0.929444\n",
      "Epoch: 181/500 Iteration: 1635 Train loss: 0.107726 Train acc: 0.966667\n",
      "Epoch: 182/500 Iteration: 1640 Train loss: 0.071433 Train acc: 0.976667\n",
      "Epoch: 182/500 Iteration: 1640 Validation loss: 0.205023 Validation acc: 0.931111\n",
      "Epoch: 182/500 Iteration: 1645 Train loss: 0.092104 Train acc: 0.970000\n",
      "Epoch: 183/500 Iteration: 1650 Train loss: 0.086903 Train acc: 0.975000\n",
      "Epoch: 183/500 Iteration: 1650 Validation loss: 0.207251 Validation acc: 0.930000\n",
      "Epoch: 183/500 Iteration: 1655 Train loss: 0.100637 Train acc: 0.960000\n",
      "Epoch: 184/500 Iteration: 1660 Train loss: 0.095770 Train acc: 0.965000\n",
      "Epoch: 184/500 Iteration: 1660 Validation loss: 0.201810 Validation acc: 0.931667\n",
      "Epoch: 184/500 Iteration: 1665 Train loss: 0.104083 Train acc: 0.965000\n",
      "Epoch: 185/500 Iteration: 1670 Train loss: 0.105141 Train acc: 0.960000\n",
      "Epoch: 185/500 Iteration: 1670 Validation loss: 0.199402 Validation acc: 0.931111\n",
      "Epoch: 186/500 Iteration: 1675 Train loss: 0.097899 Train acc: 0.970000\n",
      "Epoch: 186/500 Iteration: 1680 Train loss: 0.132830 Train acc: 0.940000\n",
      "Epoch: 186/500 Iteration: 1680 Validation loss: 0.200567 Validation acc: 0.928333\n",
      "Epoch: 187/500 Iteration: 1685 Train loss: 0.078784 Train acc: 0.976667\n",
      "Epoch: 187/500 Iteration: 1690 Train loss: 0.089765 Train acc: 0.970000\n",
      "Epoch: 187/500 Iteration: 1690 Validation loss: 0.203360 Validation acc: 0.930000\n",
      "Epoch: 188/500 Iteration: 1695 Train loss: 0.087778 Train acc: 0.970000\n",
      "Epoch: 188/500 Iteration: 1700 Train loss: 0.084743 Train acc: 0.963333\n",
      "Epoch: 188/500 Iteration: 1700 Validation loss: 0.209289 Validation acc: 0.928889\n",
      "Epoch: 189/500 Iteration: 1705 Train loss: 0.084449 Train acc: 0.968333\n",
      "Epoch: 189/500 Iteration: 1710 Train loss: 0.079123 Train acc: 0.971667\n",
      "Epoch: 189/500 Iteration: 1710 Validation loss: 0.201551 Validation acc: 0.932778\n",
      "Epoch: 190/500 Iteration: 1715 Train loss: 0.090053 Train acc: 0.971667\n",
      "Epoch: 191/500 Iteration: 1720 Train loss: 0.089450 Train acc: 0.975000\n",
      "Epoch: 191/500 Iteration: 1720 Validation loss: 0.200781 Validation acc: 0.930556\n",
      "Epoch: 191/500 Iteration: 1725 Train loss: 0.077883 Train acc: 0.968333\n",
      "Epoch: 192/500 Iteration: 1730 Train loss: 0.102476 Train acc: 0.961667\n",
      "Epoch: 192/500 Iteration: 1730 Validation loss: 0.205206 Validation acc: 0.931111\n",
      "Epoch: 192/500 Iteration: 1735 Train loss: 0.101465 Train acc: 0.963333\n",
      "Epoch: 193/500 Iteration: 1740 Train loss: 0.097426 Train acc: 0.961667\n",
      "Epoch: 193/500 Iteration: 1740 Validation loss: 0.199487 Validation acc: 0.933333\n",
      "Epoch: 193/500 Iteration: 1745 Train loss: 0.074183 Train acc: 0.973333\n",
      "Epoch: 194/500 Iteration: 1750 Train loss: 0.089251 Train acc: 0.968333\n",
      "Epoch: 194/500 Iteration: 1750 Validation loss: 0.201442 Validation acc: 0.931111\n",
      "Epoch: 194/500 Iteration: 1755 Train loss: 0.086299 Train acc: 0.970000\n",
      "Epoch: 195/500 Iteration: 1760 Train loss: 0.080921 Train acc: 0.973333\n",
      "Epoch: 195/500 Iteration: 1760 Validation loss: 0.206459 Validation acc: 0.928889\n",
      "Epoch: 196/500 Iteration: 1765 Train loss: 0.082393 Train acc: 0.968333\n",
      "Epoch: 196/500 Iteration: 1770 Train loss: 0.094832 Train acc: 0.958333\n",
      "Epoch: 196/500 Iteration: 1770 Validation loss: 0.202562 Validation acc: 0.931667\n",
      "Epoch: 197/500 Iteration: 1775 Train loss: 0.074767 Train acc: 0.968333\n",
      "Epoch: 197/500 Iteration: 1780 Train loss: 0.076930 Train acc: 0.970000\n",
      "Epoch: 197/500 Iteration: 1780 Validation loss: 0.209250 Validation acc: 0.931667\n",
      "Epoch: 198/500 Iteration: 1785 Train loss: 0.104415 Train acc: 0.951667\n",
      "Epoch: 198/500 Iteration: 1790 Train loss: 0.096439 Train acc: 0.965000\n",
      "Epoch: 198/500 Iteration: 1790 Validation loss: 0.207553 Validation acc: 0.932778\n",
      "Epoch: 199/500 Iteration: 1795 Train loss: 0.080671 Train acc: 0.966667\n",
      "Epoch: 199/500 Iteration: 1800 Train loss: 0.086794 Train acc: 0.968333\n",
      "Epoch: 199/500 Iteration: 1800 Validation loss: 0.206321 Validation acc: 0.927778\n",
      "Epoch: 200/500 Iteration: 1805 Train loss: 0.094008 Train acc: 0.966667\n",
      "Epoch: 201/500 Iteration: 1810 Train loss: 0.066978 Train acc: 0.976667\n",
      "Epoch: 201/500 Iteration: 1810 Validation loss: 0.209002 Validation acc: 0.924444\n",
      "Epoch: 201/500 Iteration: 1815 Train loss: 0.102891 Train acc: 0.963333\n",
      "Epoch: 202/500 Iteration: 1820 Train loss: 0.063406 Train acc: 0.980000\n",
      "Epoch: 202/500 Iteration: 1820 Validation loss: 0.213854 Validation acc: 0.925556\n",
      "Epoch: 202/500 Iteration: 1825 Train loss: 0.085712 Train acc: 0.968333\n",
      "Epoch: 203/500 Iteration: 1830 Train loss: 0.086884 Train acc: 0.975000\n",
      "Epoch: 203/500 Iteration: 1830 Validation loss: 0.207604 Validation acc: 0.931667\n",
      "Epoch: 203/500 Iteration: 1835 Train loss: 0.089320 Train acc: 0.960000\n",
      "Epoch: 204/500 Iteration: 1840 Train loss: 0.093753 Train acc: 0.960000\n",
      "Epoch: 204/500 Iteration: 1840 Validation loss: 0.203839 Validation acc: 0.929444\n",
      "Epoch: 204/500 Iteration: 1845 Train loss: 0.089615 Train acc: 0.971667\n",
      "Epoch: 205/500 Iteration: 1850 Train loss: 0.082787 Train acc: 0.976667\n",
      "Epoch: 205/500 Iteration: 1850 Validation loss: 0.199200 Validation acc: 0.934444\n",
      "Epoch: 206/500 Iteration: 1855 Train loss: 0.068111 Train acc: 0.976667\n",
      "Epoch: 206/500 Iteration: 1860 Train loss: 0.106242 Train acc: 0.953333\n",
      "Epoch: 206/500 Iteration: 1860 Validation loss: 0.202113 Validation acc: 0.933889\n",
      "Epoch: 207/500 Iteration: 1865 Train loss: 0.057961 Train acc: 0.981667\n",
      "Epoch: 207/500 Iteration: 1870 Train loss: 0.071282 Train acc: 0.975000\n",
      "Epoch: 207/500 Iteration: 1870 Validation loss: 0.203971 Validation acc: 0.930556\n",
      "Epoch: 208/500 Iteration: 1875 Train loss: 0.063517 Train acc: 0.983333\n",
      "Epoch: 208/500 Iteration: 1880 Train loss: 0.071314 Train acc: 0.980000\n",
      "Epoch: 208/500 Iteration: 1880 Validation loss: 0.202852 Validation acc: 0.933333\n",
      "Epoch: 209/500 Iteration: 1885 Train loss: 0.079400 Train acc: 0.976667\n",
      "Epoch: 209/500 Iteration: 1890 Train loss: 0.079486 Train acc: 0.965000\n",
      "Epoch: 209/500 Iteration: 1890 Validation loss: 0.202849 Validation acc: 0.935000\n",
      "Epoch: 210/500 Iteration: 1895 Train loss: 0.088441 Train acc: 0.965000\n",
      "Epoch: 211/500 Iteration: 1900 Train loss: 0.074239 Train acc: 0.970000\n",
      "Epoch: 211/500 Iteration: 1900 Validation loss: 0.200536 Validation acc: 0.931667\n",
      "Epoch: 211/500 Iteration: 1905 Train loss: 0.102886 Train acc: 0.961667\n",
      "Epoch: 212/500 Iteration: 1910 Train loss: 0.073822 Train acc: 0.973333\n",
      "Epoch: 212/500 Iteration: 1910 Validation loss: 0.204289 Validation acc: 0.933333\n",
      "Epoch: 212/500 Iteration: 1915 Train loss: 0.084084 Train acc: 0.961667\n",
      "Epoch: 213/500 Iteration: 1920 Train loss: 0.075704 Train acc: 0.973333\n",
      "Epoch: 213/500 Iteration: 1920 Validation loss: 0.216164 Validation acc: 0.927222\n",
      "Epoch: 213/500 Iteration: 1925 Train loss: 0.086746 Train acc: 0.970000\n",
      "Epoch: 214/500 Iteration: 1930 Train loss: 0.084751 Train acc: 0.970000\n",
      "Epoch: 214/500 Iteration: 1930 Validation loss: 0.207852 Validation acc: 0.932222\n",
      "Epoch: 214/500 Iteration: 1935 Train loss: 0.068554 Train acc: 0.968333\n",
      "Epoch: 215/500 Iteration: 1940 Train loss: 0.070287 Train acc: 0.980000\n",
      "Epoch: 215/500 Iteration: 1940 Validation loss: 0.204126 Validation acc: 0.931667\n",
      "Epoch: 216/500 Iteration: 1945 Train loss: 0.077428 Train acc: 0.973333\n",
      "Epoch: 216/500 Iteration: 1950 Train loss: 0.083500 Train acc: 0.968333\n",
      "Epoch: 216/500 Iteration: 1950 Validation loss: 0.209639 Validation acc: 0.933333\n",
      "Epoch: 217/500 Iteration: 1955 Train loss: 0.073643 Train acc: 0.965000\n",
      "Epoch: 217/500 Iteration: 1960 Train loss: 0.066742 Train acc: 0.981667\n",
      "Epoch: 217/500 Iteration: 1960 Validation loss: 0.212754 Validation acc: 0.932222\n",
      "Epoch: 218/500 Iteration: 1965 Train loss: 0.060418 Train acc: 0.978333\n",
      "Epoch: 218/500 Iteration: 1970 Train loss: 0.071271 Train acc: 0.971667\n",
      "Epoch: 218/500 Iteration: 1970 Validation loss: 0.213464 Validation acc: 0.932778\n",
      "Epoch: 219/500 Iteration: 1975 Train loss: 0.069675 Train acc: 0.971667\n",
      "Epoch: 219/500 Iteration: 1980 Train loss: 0.080287 Train acc: 0.968333\n",
      "Epoch: 219/500 Iteration: 1980 Validation loss: 0.209016 Validation acc: 0.935000\n",
      "Epoch: 220/500 Iteration: 1985 Train loss: 0.075535 Train acc: 0.975000\n",
      "Epoch: 221/500 Iteration: 1990 Train loss: 0.070735 Train acc: 0.971667\n",
      "Epoch: 221/500 Iteration: 1990 Validation loss: 0.208698 Validation acc: 0.932778\n",
      "Epoch: 221/500 Iteration: 1995 Train loss: 0.097625 Train acc: 0.961667\n",
      "Epoch: 222/500 Iteration: 2000 Train loss: 0.072500 Train acc: 0.971667\n",
      "Epoch: 222/500 Iteration: 2000 Validation loss: 0.206403 Validation acc: 0.932778\n",
      "Epoch: 222/500 Iteration: 2005 Train loss: 0.070739 Train acc: 0.975000\n",
      "Epoch: 223/500 Iteration: 2010 Train loss: 0.090272 Train acc: 0.960000\n",
      "Epoch: 223/500 Iteration: 2010 Validation loss: 0.209569 Validation acc: 0.933333\n",
      "Epoch: 223/500 Iteration: 2015 Train loss: 0.061171 Train acc: 0.983333\n",
      "Epoch: 224/500 Iteration: 2020 Train loss: 0.073794 Train acc: 0.976667\n",
      "Epoch: 224/500 Iteration: 2020 Validation loss: 0.208299 Validation acc: 0.930556\n",
      "Epoch: 224/500 Iteration: 2025 Train loss: 0.064610 Train acc: 0.981667\n",
      "Epoch: 225/500 Iteration: 2030 Train loss: 0.095928 Train acc: 0.968333\n",
      "Epoch: 225/500 Iteration: 2030 Validation loss: 0.204078 Validation acc: 0.935000\n",
      "Epoch: 226/500 Iteration: 2035 Train loss: 0.071632 Train acc: 0.973333\n",
      "Epoch: 226/500 Iteration: 2040 Train loss: 0.062252 Train acc: 0.978333\n",
      "Epoch: 226/500 Iteration: 2040 Validation loss: 0.201923 Validation acc: 0.933889\n",
      "Epoch: 227/500 Iteration: 2045 Train loss: 0.080389 Train acc: 0.968333\n",
      "Epoch: 227/500 Iteration: 2050 Train loss: 0.065332 Train acc: 0.971667\n",
      "Epoch: 227/500 Iteration: 2050 Validation loss: 0.211466 Validation acc: 0.932222\n",
      "Epoch: 228/500 Iteration: 2055 Train loss: 0.080987 Train acc: 0.965000\n",
      "Epoch: 228/500 Iteration: 2060 Train loss: 0.065240 Train acc: 0.973333\n",
      "Epoch: 228/500 Iteration: 2060 Validation loss: 0.208128 Validation acc: 0.932222\n",
      "Epoch: 229/500 Iteration: 2065 Train loss: 0.078170 Train acc: 0.973333\n",
      "Epoch: 229/500 Iteration: 2070 Train loss: 0.072060 Train acc: 0.980000\n",
      "Epoch: 229/500 Iteration: 2070 Validation loss: 0.224309 Validation acc: 0.922778\n",
      "Epoch: 230/500 Iteration: 2075 Train loss: 0.059885 Train acc: 0.978333\n",
      "Epoch: 231/500 Iteration: 2080 Train loss: 0.076311 Train acc: 0.963333\n",
      "Epoch: 231/500 Iteration: 2080 Validation loss: 0.224598 Validation acc: 0.925556\n",
      "Epoch: 231/500 Iteration: 2085 Train loss: 0.128526 Train acc: 0.950000\n",
      "Epoch: 232/500 Iteration: 2090 Train loss: 0.063893 Train acc: 0.975000\n",
      "Epoch: 232/500 Iteration: 2090 Validation loss: 0.207017 Validation acc: 0.933889\n",
      "Epoch: 232/500 Iteration: 2095 Train loss: 0.081327 Train acc: 0.966667\n",
      "Epoch: 233/500 Iteration: 2100 Train loss: 0.059866 Train acc: 0.981667\n",
      "Epoch: 233/500 Iteration: 2100 Validation loss: 0.207294 Validation acc: 0.935556\n",
      "Epoch: 233/500 Iteration: 2105 Train loss: 0.071879 Train acc: 0.968333\n",
      "Epoch: 234/500 Iteration: 2110 Train loss: 0.063836 Train acc: 0.980000\n",
      "Epoch: 234/500 Iteration: 2110 Validation loss: 0.206216 Validation acc: 0.932778\n",
      "Epoch: 234/500 Iteration: 2115 Train loss: 0.063052 Train acc: 0.980000\n",
      "Epoch: 235/500 Iteration: 2120 Train loss: 0.053781 Train acc: 0.988333\n",
      "Epoch: 235/500 Iteration: 2120 Validation loss: 0.210948 Validation acc: 0.930556\n",
      "Epoch: 236/500 Iteration: 2125 Train loss: 0.075716 Train acc: 0.968333\n",
      "Epoch: 236/500 Iteration: 2130 Train loss: 0.076619 Train acc: 0.975000\n",
      "Epoch: 236/500 Iteration: 2130 Validation loss: 0.212003 Validation acc: 0.932778\n",
      "Epoch: 237/500 Iteration: 2135 Train loss: 0.067689 Train acc: 0.980000\n",
      "Epoch: 237/500 Iteration: 2140 Train loss: 0.075206 Train acc: 0.970000\n",
      "Epoch: 237/500 Iteration: 2140 Validation loss: 0.214522 Validation acc: 0.933333\n",
      "Epoch: 238/500 Iteration: 2145 Train loss: 0.108298 Train acc: 0.963333\n",
      "Epoch: 238/500 Iteration: 2150 Train loss: 0.063040 Train acc: 0.980000\n",
      "Epoch: 238/500 Iteration: 2150 Validation loss: 0.222063 Validation acc: 0.931111\n",
      "Epoch: 239/500 Iteration: 2155 Train loss: 0.066814 Train acc: 0.975000\n",
      "Epoch: 239/500 Iteration: 2160 Train loss: 0.074792 Train acc: 0.978333\n",
      "Epoch: 239/500 Iteration: 2160 Validation loss: 0.218453 Validation acc: 0.932222\n",
      "Epoch: 240/500 Iteration: 2165 Train loss: 0.074434 Train acc: 0.966667\n",
      "Epoch: 241/500 Iteration: 2170 Train loss: 0.062539 Train acc: 0.976667\n",
      "Epoch: 241/500 Iteration: 2170 Validation loss: 0.212851 Validation acc: 0.931667\n",
      "Epoch: 241/500 Iteration: 2175 Train loss: 0.082706 Train acc: 0.976667\n",
      "Epoch: 242/500 Iteration: 2180 Train loss: 0.064748 Train acc: 0.978333\n",
      "Epoch: 242/500 Iteration: 2180 Validation loss: 0.209971 Validation acc: 0.931111\n",
      "Epoch: 242/500 Iteration: 2185 Train loss: 0.072152 Train acc: 0.976667\n",
      "Epoch: 243/500 Iteration: 2190 Train loss: 0.067833 Train acc: 0.976667\n",
      "Epoch: 243/500 Iteration: 2190 Validation loss: 0.211245 Validation acc: 0.931667\n",
      "Epoch: 243/500 Iteration: 2195 Train loss: 0.052835 Train acc: 0.983333\n",
      "Epoch: 244/500 Iteration: 2200 Train loss: 0.063605 Train acc: 0.978333\n",
      "Epoch: 244/500 Iteration: 2200 Validation loss: 0.212385 Validation acc: 0.932778\n",
      "Epoch: 244/500 Iteration: 2205 Train loss: 0.075868 Train acc: 0.968333\n",
      "Epoch: 245/500 Iteration: 2210 Train loss: 0.071799 Train acc: 0.970000\n",
      "Epoch: 245/500 Iteration: 2210 Validation loss: 0.205063 Validation acc: 0.934444\n",
      "Epoch: 246/500 Iteration: 2215 Train loss: 0.069933 Train acc: 0.970000\n",
      "Epoch: 246/500 Iteration: 2220 Train loss: 0.090481 Train acc: 0.968333\n",
      "Epoch: 246/500 Iteration: 2220 Validation loss: 0.208159 Validation acc: 0.931111\n",
      "Epoch: 247/500 Iteration: 2225 Train loss: 0.058874 Train acc: 0.981667\n",
      "Epoch: 247/500 Iteration: 2230 Train loss: 0.067402 Train acc: 0.975000\n",
      "Epoch: 247/500 Iteration: 2230 Validation loss: 0.206288 Validation acc: 0.931667\n",
      "Epoch: 248/500 Iteration: 2235 Train loss: 0.062401 Train acc: 0.980000\n",
      "Epoch: 248/500 Iteration: 2240 Train loss: 0.057394 Train acc: 0.980000\n",
      "Epoch: 248/500 Iteration: 2240 Validation loss: 0.208347 Validation acc: 0.934444\n",
      "Epoch: 249/500 Iteration: 2245 Train loss: 0.061046 Train acc: 0.978333\n",
      "Epoch: 249/500 Iteration: 2250 Train loss: 0.053761 Train acc: 0.981667\n",
      "Epoch: 249/500 Iteration: 2250 Validation loss: 0.209797 Validation acc: 0.932778\n",
      "Epoch: 250/500 Iteration: 2255 Train loss: 0.062466 Train acc: 0.978333\n",
      "Epoch: 251/500 Iteration: 2260 Train loss: 0.064009 Train acc: 0.978333\n",
      "Epoch: 251/500 Iteration: 2260 Validation loss: 0.212065 Validation acc: 0.931111\n",
      "Epoch: 251/500 Iteration: 2265 Train loss: 0.078655 Train acc: 0.966667\n",
      "Epoch: 252/500 Iteration: 2270 Train loss: 0.058834 Train acc: 0.976667\n",
      "Epoch: 252/500 Iteration: 2270 Validation loss: 0.209501 Validation acc: 0.931111\n",
      "Epoch: 252/500 Iteration: 2275 Train loss: 0.064123 Train acc: 0.973333\n",
      "Epoch: 253/500 Iteration: 2280 Train loss: 0.068088 Train acc: 0.975000\n",
      "Epoch: 253/500 Iteration: 2280 Validation loss: 0.209097 Validation acc: 0.932222\n",
      "Epoch: 253/500 Iteration: 2285 Train loss: 0.063042 Train acc: 0.971667\n",
      "Epoch: 254/500 Iteration: 2290 Train loss: 0.053425 Train acc: 0.985000\n",
      "Epoch: 254/500 Iteration: 2290 Validation loss: 0.213200 Validation acc: 0.932222\n",
      "Epoch: 254/500 Iteration: 2295 Train loss: 0.056401 Train acc: 0.980000\n",
      "Epoch: 255/500 Iteration: 2300 Train loss: 0.062763 Train acc: 0.981667\n",
      "Epoch: 255/500 Iteration: 2300 Validation loss: 0.214362 Validation acc: 0.933889\n",
      "Epoch: 256/500 Iteration: 2305 Train loss: 0.066827 Train acc: 0.983333\n",
      "Epoch: 256/500 Iteration: 2310 Train loss: 0.074881 Train acc: 0.975000\n",
      "Epoch: 256/500 Iteration: 2310 Validation loss: 0.209914 Validation acc: 0.932778\n",
      "Epoch: 257/500 Iteration: 2315 Train loss: 0.091534 Train acc: 0.963333\n",
      "Epoch: 257/500 Iteration: 2320 Train loss: 0.060906 Train acc: 0.980000\n",
      "Epoch: 257/500 Iteration: 2320 Validation loss: 0.214268 Validation acc: 0.935556\n",
      "Epoch: 258/500 Iteration: 2325 Train loss: 0.057967 Train acc: 0.975000\n",
      "Epoch: 258/500 Iteration: 2330 Train loss: 0.072125 Train acc: 0.971667\n",
      "Epoch: 258/500 Iteration: 2330 Validation loss: 0.230114 Validation acc: 0.931667\n",
      "Epoch: 259/500 Iteration: 2335 Train loss: 0.060768 Train acc: 0.981667\n",
      "Epoch: 259/500 Iteration: 2340 Train loss: 0.055018 Train acc: 0.983333\n",
      "Epoch: 259/500 Iteration: 2340 Validation loss: 0.222158 Validation acc: 0.931111\n",
      "Epoch: 260/500 Iteration: 2345 Train loss: 0.055982 Train acc: 0.981667\n",
      "Epoch: 261/500 Iteration: 2350 Train loss: 0.066073 Train acc: 0.975000\n",
      "Epoch: 261/500 Iteration: 2350 Validation loss: 0.208269 Validation acc: 0.936111\n",
      "Epoch: 261/500 Iteration: 2355 Train loss: 0.063243 Train acc: 0.975000\n",
      "Epoch: 262/500 Iteration: 2360 Train loss: 0.058117 Train acc: 0.976667\n",
      "Epoch: 262/500 Iteration: 2360 Validation loss: 0.213440 Validation acc: 0.932778\n",
      "Epoch: 262/500 Iteration: 2365 Train loss: 0.056152 Train acc: 0.975000\n",
      "Epoch: 263/500 Iteration: 2370 Train loss: 0.053400 Train acc: 0.978333\n",
      "Epoch: 263/500 Iteration: 2370 Validation loss: 0.207699 Validation acc: 0.933333\n",
      "Epoch: 263/500 Iteration: 2375 Train loss: 0.054801 Train acc: 0.981667\n",
      "Epoch: 264/500 Iteration: 2380 Train loss: 0.051286 Train acc: 0.983333\n",
      "Epoch: 264/500 Iteration: 2380 Validation loss: 0.212124 Validation acc: 0.931111\n",
      "Epoch: 264/500 Iteration: 2385 Train loss: 0.049999 Train acc: 0.981667\n",
      "Epoch: 265/500 Iteration: 2390 Train loss: 0.052394 Train acc: 0.981667\n",
      "Epoch: 265/500 Iteration: 2390 Validation loss: 0.208496 Validation acc: 0.933889\n",
      "Epoch: 266/500 Iteration: 2395 Train loss: 0.063196 Train acc: 0.976667\n",
      "Epoch: 266/500 Iteration: 2400 Train loss: 0.078512 Train acc: 0.970000\n",
      "Epoch: 266/500 Iteration: 2400 Validation loss: 0.206540 Validation acc: 0.936111\n",
      "Epoch: 267/500 Iteration: 2405 Train loss: 0.047305 Train acc: 0.981667\n",
      "Epoch: 267/500 Iteration: 2410 Train loss: 0.064707 Train acc: 0.975000\n",
      "Epoch: 267/500 Iteration: 2410 Validation loss: 0.210306 Validation acc: 0.933333\n",
      "Epoch: 268/500 Iteration: 2415 Train loss: 0.064489 Train acc: 0.976667\n",
      "Epoch: 268/500 Iteration: 2420 Train loss: 0.053279 Train acc: 0.975000\n",
      "Epoch: 268/500 Iteration: 2420 Validation loss: 0.211546 Validation acc: 0.932222\n",
      "Epoch: 269/500 Iteration: 2425 Train loss: 0.048640 Train acc: 0.983333\n",
      "Epoch: 269/500 Iteration: 2430 Train loss: 0.065571 Train acc: 0.978333\n",
      "Epoch: 269/500 Iteration: 2430 Validation loss: 0.221472 Validation acc: 0.933333\n",
      "Epoch: 270/500 Iteration: 2435 Train loss: 0.054546 Train acc: 0.980000\n",
      "Epoch: 271/500 Iteration: 2440 Train loss: 0.052397 Train acc: 0.978333\n",
      "Epoch: 271/500 Iteration: 2440 Validation loss: 0.217270 Validation acc: 0.933889\n",
      "Epoch: 271/500 Iteration: 2445 Train loss: 0.058287 Train acc: 0.980000\n",
      "Epoch: 272/500 Iteration: 2450 Train loss: 0.063919 Train acc: 0.983333\n",
      "Epoch: 272/500 Iteration: 2450 Validation loss: 0.218500 Validation acc: 0.935556\n",
      "Epoch: 272/500 Iteration: 2455 Train loss: 0.045412 Train acc: 0.985000\n",
      "Epoch: 273/500 Iteration: 2460 Train loss: 0.061028 Train acc: 0.983333\n",
      "Epoch: 273/500 Iteration: 2460 Validation loss: 0.214141 Validation acc: 0.933889\n",
      "Epoch: 273/500 Iteration: 2465 Train loss: 0.070578 Train acc: 0.975000\n",
      "Epoch: 274/500 Iteration: 2470 Train loss: 0.043815 Train acc: 0.983333\n",
      "Epoch: 274/500 Iteration: 2470 Validation loss: 0.212621 Validation acc: 0.932222\n",
      "Epoch: 274/500 Iteration: 2475 Train loss: 0.054231 Train acc: 0.980000\n",
      "Epoch: 275/500 Iteration: 2480 Train loss: 0.061652 Train acc: 0.980000\n",
      "Epoch: 275/500 Iteration: 2480 Validation loss: 0.216517 Validation acc: 0.934444\n",
      "Epoch: 276/500 Iteration: 2485 Train loss: 0.045011 Train acc: 0.986667\n",
      "Epoch: 276/500 Iteration: 2490 Train loss: 0.067512 Train acc: 0.976667\n",
      "Epoch: 276/500 Iteration: 2490 Validation loss: 0.218421 Validation acc: 0.934444\n",
      "Epoch: 277/500 Iteration: 2495 Train loss: 0.057568 Train acc: 0.978333\n",
      "Epoch: 277/500 Iteration: 2500 Train loss: 0.052095 Train acc: 0.978333\n",
      "Epoch: 277/500 Iteration: 2500 Validation loss: 0.218660 Validation acc: 0.936111\n",
      "Epoch: 278/500 Iteration: 2505 Train loss: 0.053635 Train acc: 0.983333\n",
      "Epoch: 278/500 Iteration: 2510 Train loss: 0.052238 Train acc: 0.981667\n",
      "Epoch: 278/500 Iteration: 2510 Validation loss: 0.218318 Validation acc: 0.929444\n",
      "Epoch: 279/500 Iteration: 2515 Train loss: 0.045723 Train acc: 0.983333\n",
      "Epoch: 279/500 Iteration: 2520 Train loss: 0.045145 Train acc: 0.981667\n",
      "Epoch: 279/500 Iteration: 2520 Validation loss: 0.212866 Validation acc: 0.932778\n",
      "Epoch: 280/500 Iteration: 2525 Train loss: 0.068788 Train acc: 0.971667\n",
      "Epoch: 281/500 Iteration: 2530 Train loss: 0.055355 Train acc: 0.985000\n",
      "Epoch: 281/500 Iteration: 2530 Validation loss: 0.213698 Validation acc: 0.932778\n",
      "Epoch: 281/500 Iteration: 2535 Train loss: 0.062447 Train acc: 0.978333\n",
      "Epoch: 282/500 Iteration: 2540 Train loss: 0.053696 Train acc: 0.981667\n",
      "Epoch: 282/500 Iteration: 2540 Validation loss: 0.215150 Validation acc: 0.936667\n",
      "Epoch: 282/500 Iteration: 2545 Train loss: 0.054440 Train acc: 0.976667\n",
      "Epoch: 283/500 Iteration: 2550 Train loss: 0.065419 Train acc: 0.976667\n",
      "Epoch: 283/500 Iteration: 2550 Validation loss: 0.218675 Validation acc: 0.933333\n",
      "Epoch: 283/500 Iteration: 2555 Train loss: 0.055907 Train acc: 0.985000\n",
      "Epoch: 284/500 Iteration: 2560 Train loss: 0.057690 Train acc: 0.978333\n",
      "Epoch: 284/500 Iteration: 2560 Validation loss: 0.214492 Validation acc: 0.932222\n",
      "Epoch: 284/500 Iteration: 2565 Train loss: 0.064546 Train acc: 0.975000\n",
      "Epoch: 285/500 Iteration: 2570 Train loss: 0.062999 Train acc: 0.978333\n",
      "Epoch: 285/500 Iteration: 2570 Validation loss: 0.209648 Validation acc: 0.933889\n",
      "Epoch: 286/500 Iteration: 2575 Train loss: 0.063299 Train acc: 0.975000\n",
      "Epoch: 286/500 Iteration: 2580 Train loss: 0.061923 Train acc: 0.978333\n",
      "Epoch: 286/500 Iteration: 2580 Validation loss: 0.213884 Validation acc: 0.932778\n",
      "Epoch: 287/500 Iteration: 2585 Train loss: 0.060586 Train acc: 0.980000\n",
      "Epoch: 287/500 Iteration: 2590 Train loss: 0.053449 Train acc: 0.983333\n",
      "Epoch: 287/500 Iteration: 2590 Validation loss: 0.218742 Validation acc: 0.933333\n",
      "Epoch: 288/500 Iteration: 2595 Train loss: 0.047540 Train acc: 0.983333\n",
      "Epoch: 288/500 Iteration: 2600 Train loss: 0.065386 Train acc: 0.971667\n",
      "Epoch: 288/500 Iteration: 2600 Validation loss: 0.215775 Validation acc: 0.932222\n",
      "Epoch: 289/500 Iteration: 2605 Train loss: 0.043788 Train acc: 0.983333\n",
      "Epoch: 289/500 Iteration: 2610 Train loss: 0.044112 Train acc: 0.985000\n",
      "Epoch: 289/500 Iteration: 2610 Validation loss: 0.220357 Validation acc: 0.934444\n",
      "Epoch: 290/500 Iteration: 2615 Train loss: 0.053424 Train acc: 0.981667\n",
      "Epoch: 291/500 Iteration: 2620 Train loss: 0.076629 Train acc: 0.973333\n",
      "Epoch: 291/500 Iteration: 2620 Validation loss: 0.217096 Validation acc: 0.932778\n",
      "Epoch: 291/500 Iteration: 2625 Train loss: 0.064606 Train acc: 0.971667\n",
      "Epoch: 292/500 Iteration: 2630 Train loss: 0.071025 Train acc: 0.973333\n",
      "Epoch: 292/500 Iteration: 2630 Validation loss: 0.217047 Validation acc: 0.937222\n",
      "Epoch: 292/500 Iteration: 2635 Train loss: 0.061731 Train acc: 0.975000\n",
      "Epoch: 293/500 Iteration: 2640 Train loss: 0.057710 Train acc: 0.980000\n",
      "Epoch: 293/500 Iteration: 2640 Validation loss: 0.220340 Validation acc: 0.930556\n",
      "Epoch: 293/500 Iteration: 2645 Train loss: 0.059250 Train acc: 0.978333\n",
      "Epoch: 294/500 Iteration: 2650 Train loss: 0.059762 Train acc: 0.973333\n",
      "Epoch: 294/500 Iteration: 2650 Validation loss: 0.220535 Validation acc: 0.931111\n",
      "Epoch: 294/500 Iteration: 2655 Train loss: 0.046268 Train acc: 0.986667\n",
      "Epoch: 295/500 Iteration: 2660 Train loss: 0.047925 Train acc: 0.986667\n",
      "Epoch: 295/500 Iteration: 2660 Validation loss: 0.225920 Validation acc: 0.935555\n",
      "Epoch: 296/500 Iteration: 2665 Train loss: 0.059701 Train acc: 0.976667\n",
      "Epoch: 296/500 Iteration: 2670 Train loss: 0.066966 Train acc: 0.980000\n",
      "Epoch: 296/500 Iteration: 2670 Validation loss: 0.220472 Validation acc: 0.934444\n",
      "Epoch: 297/500 Iteration: 2675 Train loss: 0.048908 Train acc: 0.983333\n",
      "Epoch: 297/500 Iteration: 2680 Train loss: 0.059707 Train acc: 0.986667\n",
      "Epoch: 297/500 Iteration: 2680 Validation loss: 0.214569 Validation acc: 0.933889\n",
      "Epoch: 298/500 Iteration: 2685 Train loss: 0.057658 Train acc: 0.981667\n",
      "Epoch: 298/500 Iteration: 2690 Train loss: 0.064622 Train acc: 0.978333\n",
      "Epoch: 298/500 Iteration: 2690 Validation loss: 0.214900 Validation acc: 0.935000\n",
      "Epoch: 299/500 Iteration: 2695 Train loss: 0.053261 Train acc: 0.978333\n",
      "Epoch: 299/500 Iteration: 2700 Train loss: 0.038920 Train acc: 0.988333\n",
      "Epoch: 299/500 Iteration: 2700 Validation loss: 0.221190 Validation acc: 0.935556\n",
      "Epoch: 300/500 Iteration: 2705 Train loss: 0.066116 Train acc: 0.968333\n",
      "Epoch: 301/500 Iteration: 2710 Train loss: 0.060058 Train acc: 0.981667\n",
      "Epoch: 301/500 Iteration: 2710 Validation loss: 0.218501 Validation acc: 0.933889\n",
      "Epoch: 301/500 Iteration: 2715 Train loss: 0.068178 Train acc: 0.978333\n",
      "Epoch: 302/500 Iteration: 2720 Train loss: 0.067082 Train acc: 0.971667\n",
      "Epoch: 302/500 Iteration: 2720 Validation loss: 0.216837 Validation acc: 0.934444\n",
      "Epoch: 302/500 Iteration: 2725 Train loss: 0.049002 Train acc: 0.985000\n",
      "Epoch: 303/500 Iteration: 2730 Train loss: 0.055621 Train acc: 0.975000\n",
      "Epoch: 303/500 Iteration: 2730 Validation loss: 0.216850 Validation acc: 0.932778\n",
      "Epoch: 303/500 Iteration: 2735 Train loss: 0.061702 Train acc: 0.976667\n",
      "Epoch: 304/500 Iteration: 2740 Train loss: 0.050838 Train acc: 0.986667\n",
      "Epoch: 304/500 Iteration: 2740 Validation loss: 0.218362 Validation acc: 0.933333\n",
      "Epoch: 304/500 Iteration: 2745 Train loss: 0.044493 Train acc: 0.991667\n",
      "Epoch: 305/500 Iteration: 2750 Train loss: 0.064490 Train acc: 0.973333\n",
      "Epoch: 305/500 Iteration: 2750 Validation loss: 0.219050 Validation acc: 0.935000\n",
      "Epoch: 306/500 Iteration: 2755 Train loss: 0.054938 Train acc: 0.976667\n",
      "Epoch: 306/500 Iteration: 2760 Train loss: 0.049621 Train acc: 0.983333\n",
      "Epoch: 306/500 Iteration: 2760 Validation loss: 0.217927 Validation acc: 0.934444\n",
      "Epoch: 307/500 Iteration: 2765 Train loss: 0.052953 Train acc: 0.978333\n",
      "Epoch: 307/500 Iteration: 2770 Train loss: 0.048335 Train acc: 0.985000\n",
      "Epoch: 307/500 Iteration: 2770 Validation loss: 0.217780 Validation acc: 0.934444\n",
      "Epoch: 308/500 Iteration: 2775 Train loss: 0.034563 Train acc: 0.993333\n",
      "Epoch: 308/500 Iteration: 2780 Train loss: 0.065132 Train acc: 0.976667\n",
      "Epoch: 308/500 Iteration: 2780 Validation loss: 0.217419 Validation acc: 0.935556\n",
      "Epoch: 309/500 Iteration: 2785 Train loss: 0.047511 Train acc: 0.986667\n",
      "Epoch: 309/500 Iteration: 2790 Train loss: 0.054183 Train acc: 0.978333\n",
      "Epoch: 309/500 Iteration: 2790 Validation loss: 0.214519 Validation acc: 0.933889\n",
      "Epoch: 310/500 Iteration: 2795 Train loss: 0.030098 Train acc: 0.996667\n",
      "Epoch: 311/500 Iteration: 2800 Train loss: 0.050994 Train acc: 0.978333\n",
      "Epoch: 311/500 Iteration: 2800 Validation loss: 0.221441 Validation acc: 0.932778\n",
      "Epoch: 311/500 Iteration: 2805 Train loss: 0.062792 Train acc: 0.981667\n",
      "Epoch: 312/500 Iteration: 2810 Train loss: 0.052269 Train acc: 0.985000\n",
      "Epoch: 312/500 Iteration: 2810 Validation loss: 0.221128 Validation acc: 0.932222\n",
      "Epoch: 312/500 Iteration: 2815 Train loss: 0.055988 Train acc: 0.978333\n",
      "Epoch: 313/500 Iteration: 2820 Train loss: 0.047408 Train acc: 0.981667\n",
      "Epoch: 313/500 Iteration: 2820 Validation loss: 0.212435 Validation acc: 0.931111\n",
      "Epoch: 313/500 Iteration: 2825 Train loss: 0.060313 Train acc: 0.966667\n",
      "Epoch: 314/500 Iteration: 2830 Train loss: 0.051404 Train acc: 0.988333\n",
      "Epoch: 314/500 Iteration: 2830 Validation loss: 0.211164 Validation acc: 0.931667\n",
      "Epoch: 314/500 Iteration: 2835 Train loss: 0.040128 Train acc: 0.981667\n",
      "Epoch: 315/500 Iteration: 2840 Train loss: 0.048895 Train acc: 0.983333\n",
      "Epoch: 315/500 Iteration: 2840 Validation loss: 0.219543 Validation acc: 0.935555\n",
      "Epoch: 316/500 Iteration: 2845 Train loss: 0.054097 Train acc: 0.978333\n",
      "Epoch: 316/500 Iteration: 2850 Train loss: 0.077278 Train acc: 0.968333\n",
      "Epoch: 316/500 Iteration: 2850 Validation loss: 0.220747 Validation acc: 0.935555\n",
      "Epoch: 317/500 Iteration: 2855 Train loss: 0.040587 Train acc: 0.983333\n",
      "Epoch: 317/500 Iteration: 2860 Train loss: 0.036537 Train acc: 0.988333\n",
      "Epoch: 317/500 Iteration: 2860 Validation loss: 0.227679 Validation acc: 0.936667\n",
      "Epoch: 318/500 Iteration: 2865 Train loss: 0.049363 Train acc: 0.980000\n",
      "Epoch: 318/500 Iteration: 2870 Train loss: 0.052654 Train acc: 0.983333\n",
      "Epoch: 318/500 Iteration: 2870 Validation loss: 0.227541 Validation acc: 0.936111\n",
      "Epoch: 319/500 Iteration: 2875 Train loss: 0.037999 Train acc: 0.988333\n",
      "Epoch: 319/500 Iteration: 2880 Train loss: 0.055747 Train acc: 0.976667\n",
      "Epoch: 319/500 Iteration: 2880 Validation loss: 0.227180 Validation acc: 0.934444\n",
      "Epoch: 320/500 Iteration: 2885 Train loss: 0.040522 Train acc: 0.983333\n",
      "Epoch: 321/500 Iteration: 2890 Train loss: 0.058005 Train acc: 0.976667\n",
      "Epoch: 321/500 Iteration: 2890 Validation loss: 0.219877 Validation acc: 0.935556\n",
      "Epoch: 321/500 Iteration: 2895 Train loss: 0.061471 Train acc: 0.970000\n",
      "Epoch: 322/500 Iteration: 2900 Train loss: 0.048435 Train acc: 0.978333\n",
      "Epoch: 322/500 Iteration: 2900 Validation loss: 0.216131 Validation acc: 0.936667\n",
      "Epoch: 322/500 Iteration: 2905 Train loss: 0.044739 Train acc: 0.983333\n",
      "Epoch: 323/500 Iteration: 2910 Train loss: 0.034065 Train acc: 0.988333\n",
      "Epoch: 323/500 Iteration: 2910 Validation loss: 0.219834 Validation acc: 0.935555\n",
      "Epoch: 323/500 Iteration: 2915 Train loss: 0.042929 Train acc: 0.988333\n",
      "Epoch: 324/500 Iteration: 2920 Train loss: 0.045003 Train acc: 0.980000\n",
      "Epoch: 324/500 Iteration: 2920 Validation loss: 0.219620 Validation acc: 0.936111\n",
      "Epoch: 324/500 Iteration: 2925 Train loss: 0.055869 Train acc: 0.981667\n",
      "Epoch: 325/500 Iteration: 2930 Train loss: 0.065595 Train acc: 0.978333\n",
      "Epoch: 325/500 Iteration: 2930 Validation loss: 0.215356 Validation acc: 0.930556\n",
      "Epoch: 326/500 Iteration: 2935 Train loss: 0.040965 Train acc: 0.988333\n",
      "Epoch: 326/500 Iteration: 2940 Train loss: 0.052598 Train acc: 0.978333\n",
      "Epoch: 326/500 Iteration: 2940 Validation loss: 0.221415 Validation acc: 0.935000\n",
      "Epoch: 327/500 Iteration: 2945 Train loss: 0.050271 Train acc: 0.981667\n",
      "Epoch: 327/500 Iteration: 2950 Train loss: 0.056073 Train acc: 0.981667\n",
      "Epoch: 327/500 Iteration: 2950 Validation loss: 0.219916 Validation acc: 0.931667\n",
      "Epoch: 328/500 Iteration: 2955 Train loss: 0.070872 Train acc: 0.978333\n",
      "Epoch: 328/500 Iteration: 2960 Train loss: 0.052193 Train acc: 0.980000\n",
      "Epoch: 328/500 Iteration: 2960 Validation loss: 0.220941 Validation acc: 0.932778\n",
      "Epoch: 329/500 Iteration: 2965 Train loss: 0.037611 Train acc: 0.993333\n",
      "Epoch: 329/500 Iteration: 2970 Train loss: 0.043757 Train acc: 0.983333\n",
      "Epoch: 329/500 Iteration: 2970 Validation loss: 0.236362 Validation acc: 0.935000\n",
      "Epoch: 330/500 Iteration: 2975 Train loss: 0.053398 Train acc: 0.980000\n",
      "Epoch: 331/500 Iteration: 2980 Train loss: 0.050884 Train acc: 0.981667\n",
      "Epoch: 331/500 Iteration: 2980 Validation loss: 0.231953 Validation acc: 0.934444\n",
      "Epoch: 331/500 Iteration: 2985 Train loss: 0.045620 Train acc: 0.985000\n",
      "Epoch: 332/500 Iteration: 2990 Train loss: 0.052252 Train acc: 0.986667\n",
      "Epoch: 332/500 Iteration: 2990 Validation loss: 0.222305 Validation acc: 0.932778\n",
      "Epoch: 332/500 Iteration: 2995 Train loss: 0.040260 Train acc: 0.985000\n",
      "Epoch: 333/500 Iteration: 3000 Train loss: 0.042671 Train acc: 0.983333\n",
      "Epoch: 333/500 Iteration: 3000 Validation loss: 0.219741 Validation acc: 0.933889\n",
      "Epoch: 333/500 Iteration: 3005 Train loss: 0.065330 Train acc: 0.968333\n",
      "Epoch: 334/500 Iteration: 3010 Train loss: 0.046628 Train acc: 0.981667\n",
      "Epoch: 334/500 Iteration: 3010 Validation loss: 0.217266 Validation acc: 0.931111\n",
      "Epoch: 334/500 Iteration: 3015 Train loss: 0.059823 Train acc: 0.985000\n",
      "Epoch: 335/500 Iteration: 3020 Train loss: 0.056408 Train acc: 0.978333\n",
      "Epoch: 335/500 Iteration: 3020 Validation loss: 0.223768 Validation acc: 0.932778\n",
      "Epoch: 336/500 Iteration: 3025 Train loss: 0.029517 Train acc: 0.990000\n",
      "Epoch: 336/500 Iteration: 3030 Train loss: 0.057097 Train acc: 0.978333\n",
      "Epoch: 336/500 Iteration: 3030 Validation loss: 0.228173 Validation acc: 0.934444\n",
      "Epoch: 337/500 Iteration: 3035 Train loss: 0.042156 Train acc: 0.985000\n",
      "Epoch: 337/500 Iteration: 3040 Train loss: 0.056190 Train acc: 0.983333\n",
      "Epoch: 337/500 Iteration: 3040 Validation loss: 0.222014 Validation acc: 0.937222\n",
      "Epoch: 338/500 Iteration: 3045 Train loss: 0.049377 Train acc: 0.990000\n",
      "Epoch: 338/500 Iteration: 3050 Train loss: 0.040970 Train acc: 0.988333\n",
      "Epoch: 338/500 Iteration: 3050 Validation loss: 0.226745 Validation acc: 0.936667\n",
      "Epoch: 339/500 Iteration: 3055 Train loss: 0.059038 Train acc: 0.980000\n",
      "Epoch: 339/500 Iteration: 3060 Train loss: 0.042401 Train acc: 0.988333\n",
      "Epoch: 339/500 Iteration: 3060 Validation loss: 0.222468 Validation acc: 0.933889\n",
      "Epoch: 340/500 Iteration: 3065 Train loss: 0.045642 Train acc: 0.983333\n",
      "Epoch: 341/500 Iteration: 3070 Train loss: 0.046995 Train acc: 0.986667\n",
      "Epoch: 341/500 Iteration: 3070 Validation loss: 0.226638 Validation acc: 0.931667\n",
      "Epoch: 341/500 Iteration: 3075 Train loss: 0.071651 Train acc: 0.973333\n",
      "Epoch: 342/500 Iteration: 3080 Train loss: 0.037963 Train acc: 0.986667\n",
      "Epoch: 342/500 Iteration: 3080 Validation loss: 0.218114 Validation acc: 0.935556\n",
      "Epoch: 342/500 Iteration: 3085 Train loss: 0.056643 Train acc: 0.978333\n",
      "Epoch: 343/500 Iteration: 3090 Train loss: 0.036329 Train acc: 0.981667\n",
      "Epoch: 343/500 Iteration: 3090 Validation loss: 0.222703 Validation acc: 0.935555\n",
      "Epoch: 343/500 Iteration: 3095 Train loss: 0.040689 Train acc: 0.986667\n",
      "Epoch: 344/500 Iteration: 3100 Train loss: 0.061572 Train acc: 0.983333\n",
      "Epoch: 344/500 Iteration: 3100 Validation loss: 0.228258 Validation acc: 0.934444\n",
      "Epoch: 344/500 Iteration: 3105 Train loss: 0.024896 Train acc: 0.995000\n",
      "Epoch: 345/500 Iteration: 3110 Train loss: 0.048665 Train acc: 0.980000\n",
      "Epoch: 345/500 Iteration: 3110 Validation loss: 0.229200 Validation acc: 0.935555\n",
      "Epoch: 346/500 Iteration: 3115 Train loss: 0.068977 Train acc: 0.973333\n",
      "Epoch: 346/500 Iteration: 3120 Train loss: 0.053820 Train acc: 0.976667\n",
      "Epoch: 346/500 Iteration: 3120 Validation loss: 0.219908 Validation acc: 0.933333\n",
      "Epoch: 347/500 Iteration: 3125 Train loss: 0.046003 Train acc: 0.978333\n",
      "Epoch: 347/500 Iteration: 3130 Train loss: 0.052632 Train acc: 0.980000\n",
      "Epoch: 347/500 Iteration: 3130 Validation loss: 0.222421 Validation acc: 0.933333\n",
      "Epoch: 348/500 Iteration: 3135 Train loss: 0.022953 Train acc: 0.993333\n",
      "Epoch: 348/500 Iteration: 3140 Train loss: 0.043259 Train acc: 0.988333\n",
      "Epoch: 348/500 Iteration: 3140 Validation loss: 0.222848 Validation acc: 0.936111\n",
      "Epoch: 349/500 Iteration: 3145 Train loss: 0.038484 Train acc: 0.985000\n",
      "Epoch: 349/500 Iteration: 3150 Train loss: 0.043772 Train acc: 0.981667\n",
      "Epoch: 349/500 Iteration: 3150 Validation loss: 0.220350 Validation acc: 0.933333\n",
      "Epoch: 350/500 Iteration: 3155 Train loss: 0.034945 Train acc: 0.988333\n",
      "Epoch: 351/500 Iteration: 3160 Train loss: 0.040536 Train acc: 0.985000\n",
      "Epoch: 351/500 Iteration: 3160 Validation loss: 0.222113 Validation acc: 0.933333\n",
      "Epoch: 351/500 Iteration: 3165 Train loss: 0.046967 Train acc: 0.983333\n",
      "Epoch: 352/500 Iteration: 3170 Train loss: 0.027252 Train acc: 0.991667\n",
      "Epoch: 352/500 Iteration: 3170 Validation loss: 0.222552 Validation acc: 0.932222\n",
      "Epoch: 352/500 Iteration: 3175 Train loss: 0.048420 Train acc: 0.986667\n",
      "Epoch: 353/500 Iteration: 3180 Train loss: 0.037839 Train acc: 0.986667\n",
      "Epoch: 353/500 Iteration: 3180 Validation loss: 0.220267 Validation acc: 0.932778\n",
      "Epoch: 353/500 Iteration: 3185 Train loss: 0.041206 Train acc: 0.985000\n",
      "Epoch: 354/500 Iteration: 3190 Train loss: 0.046291 Train acc: 0.986667\n",
      "Epoch: 354/500 Iteration: 3190 Validation loss: 0.225879 Validation acc: 0.932778\n",
      "Epoch: 354/500 Iteration: 3195 Train loss: 0.041788 Train acc: 0.986667\n",
      "Epoch: 355/500 Iteration: 3200 Train loss: 0.044105 Train acc: 0.985000\n",
      "Epoch: 355/500 Iteration: 3200 Validation loss: 0.227150 Validation acc: 0.933333\n",
      "Epoch: 356/500 Iteration: 3205 Train loss: 0.038135 Train acc: 0.986667\n",
      "Epoch: 356/500 Iteration: 3210 Train loss: 0.049175 Train acc: 0.983333\n",
      "Epoch: 356/500 Iteration: 3210 Validation loss: 0.227398 Validation acc: 0.936111\n",
      "Epoch: 357/500 Iteration: 3215 Train loss: 0.030110 Train acc: 0.988333\n",
      "Epoch: 357/500 Iteration: 3220 Train loss: 0.041078 Train acc: 0.985000\n",
      "Epoch: 357/500 Iteration: 3220 Validation loss: 0.228334 Validation acc: 0.934444\n",
      "Epoch: 358/500 Iteration: 3225 Train loss: 0.030602 Train acc: 0.988333\n",
      "Epoch: 358/500 Iteration: 3230 Train loss: 0.042369 Train acc: 0.988333\n",
      "Epoch: 358/500 Iteration: 3230 Validation loss: 0.233686 Validation acc: 0.936667\n",
      "Epoch: 359/500 Iteration: 3235 Train loss: 0.041147 Train acc: 0.986667\n",
      "Epoch: 359/500 Iteration: 3240 Train loss: 0.059062 Train acc: 0.980000\n",
      "Epoch: 359/500 Iteration: 3240 Validation loss: 0.226049 Validation acc: 0.933333\n",
      "Epoch: 360/500 Iteration: 3245 Train loss: 0.050569 Train acc: 0.980000\n",
      "Epoch: 361/500 Iteration: 3250 Train loss: 0.039639 Train acc: 0.986667\n",
      "Epoch: 361/500 Iteration: 3250 Validation loss: 0.226568 Validation acc: 0.935555\n",
      "Epoch: 361/500 Iteration: 3255 Train loss: 0.050368 Train acc: 0.985000\n",
      "Epoch: 362/500 Iteration: 3260 Train loss: 0.050197 Train acc: 0.981667\n",
      "Epoch: 362/500 Iteration: 3260 Validation loss: 0.228268 Validation acc: 0.936667\n",
      "Epoch: 362/500 Iteration: 3265 Train loss: 0.045881 Train acc: 0.985000\n",
      "Epoch: 363/500 Iteration: 3270 Train loss: 0.031908 Train acc: 0.988333\n",
      "Epoch: 363/500 Iteration: 3270 Validation loss: 0.227011 Validation acc: 0.935000\n",
      "Epoch: 363/500 Iteration: 3275 Train loss: 0.051005 Train acc: 0.986667\n",
      "Epoch: 364/500 Iteration: 3280 Train loss: 0.034834 Train acc: 0.991667\n",
      "Epoch: 364/500 Iteration: 3280 Validation loss: 0.228273 Validation acc: 0.936111\n",
      "Epoch: 364/500 Iteration: 3285 Train loss: 0.042777 Train acc: 0.986667\n",
      "Epoch: 365/500 Iteration: 3290 Train loss: 0.039477 Train acc: 0.985000\n",
      "Epoch: 365/500 Iteration: 3290 Validation loss: 0.232350 Validation acc: 0.935556\n",
      "Epoch: 366/500 Iteration: 3295 Train loss: 0.071039 Train acc: 0.970000\n",
      "Epoch: 366/500 Iteration: 3300 Train loss: 0.066035 Train acc: 0.976667\n",
      "Epoch: 366/500 Iteration: 3300 Validation loss: 0.226042 Validation acc: 0.934444\n",
      "Epoch: 367/500 Iteration: 3305 Train loss: 0.033469 Train acc: 0.991667\n",
      "Epoch: 367/500 Iteration: 3310 Train loss: 0.044175 Train acc: 0.980000\n",
      "Epoch: 367/500 Iteration: 3310 Validation loss: 0.228962 Validation acc: 0.936111\n",
      "Epoch: 368/500 Iteration: 3315 Train loss: 0.039316 Train acc: 0.986667\n",
      "Epoch: 368/500 Iteration: 3320 Train loss: 0.050048 Train acc: 0.983333\n",
      "Epoch: 368/500 Iteration: 3320 Validation loss: 0.233638 Validation acc: 0.935556\n",
      "Epoch: 369/500 Iteration: 3325 Train loss: 0.043696 Train acc: 0.988333\n",
      "Epoch: 369/500 Iteration: 3330 Train loss: 0.035072 Train acc: 0.990000\n",
      "Epoch: 369/500 Iteration: 3330 Validation loss: 0.229504 Validation acc: 0.935556\n",
      "Epoch: 370/500 Iteration: 3335 Train loss: 0.043063 Train acc: 0.985000\n",
      "Epoch: 371/500 Iteration: 3340 Train loss: 0.045336 Train acc: 0.976667\n",
      "Epoch: 371/500 Iteration: 3340 Validation loss: 0.227398 Validation acc: 0.933889\n",
      "Epoch: 371/500 Iteration: 3345 Train loss: 0.036756 Train acc: 0.988333\n",
      "Epoch: 372/500 Iteration: 3350 Train loss: 0.046784 Train acc: 0.983333\n",
      "Epoch: 372/500 Iteration: 3350 Validation loss: 0.231052 Validation acc: 0.933889\n",
      "Epoch: 372/500 Iteration: 3355 Train loss: 0.072662 Train acc: 0.970000\n",
      "Epoch: 373/500 Iteration: 3360 Train loss: 0.038322 Train acc: 0.985000\n",
      "Epoch: 373/500 Iteration: 3360 Validation loss: 0.231145 Validation acc: 0.937778\n",
      "Epoch: 373/500 Iteration: 3365 Train loss: 0.048081 Train acc: 0.985000\n",
      "Epoch: 374/500 Iteration: 3370 Train loss: 0.034080 Train acc: 0.990000\n",
      "Epoch: 374/500 Iteration: 3370 Validation loss: 0.226776 Validation acc: 0.933889\n",
      "Epoch: 374/500 Iteration: 3375 Train loss: 0.038287 Train acc: 0.988333\n",
      "Epoch: 375/500 Iteration: 3380 Train loss: 0.040585 Train acc: 0.980000\n",
      "Epoch: 375/500 Iteration: 3380 Validation loss: 0.226462 Validation acc: 0.936111\n",
      "Epoch: 376/500 Iteration: 3385 Train loss: 0.040821 Train acc: 0.986667\n",
      "Epoch: 376/500 Iteration: 3390 Train loss: 0.057598 Train acc: 0.980000\n",
      "Epoch: 376/500 Iteration: 3390 Validation loss: 0.228446 Validation acc: 0.933333\n",
      "Epoch: 377/500 Iteration: 3395 Train loss: 0.038715 Train acc: 0.991667\n",
      "Epoch: 377/500 Iteration: 3400 Train loss: 0.043271 Train acc: 0.985000\n",
      "Epoch: 377/500 Iteration: 3400 Validation loss: 0.227677 Validation acc: 0.933889\n",
      "Epoch: 378/500 Iteration: 3405 Train loss: 0.032352 Train acc: 0.991667\n",
      "Epoch: 378/500 Iteration: 3410 Train loss: 0.040362 Train acc: 0.986667\n",
      "Epoch: 378/500 Iteration: 3410 Validation loss: 0.225982 Validation acc: 0.936111\n",
      "Epoch: 379/500 Iteration: 3415 Train loss: 0.042615 Train acc: 0.988333\n",
      "Epoch: 379/500 Iteration: 3420 Train loss: 0.045879 Train acc: 0.986667\n",
      "Epoch: 379/500 Iteration: 3420 Validation loss: 0.230581 Validation acc: 0.936667\n",
      "Epoch: 380/500 Iteration: 3425 Train loss: 0.042665 Train acc: 0.985000\n",
      "Epoch: 381/500 Iteration: 3430 Train loss: 0.042593 Train acc: 0.983333\n",
      "Epoch: 381/500 Iteration: 3430 Validation loss: 0.227888 Validation acc: 0.935000\n",
      "Epoch: 381/500 Iteration: 3435 Train loss: 0.045177 Train acc: 0.985000\n",
      "Epoch: 382/500 Iteration: 3440 Train loss: 0.034942 Train acc: 0.991667\n",
      "Epoch: 382/500 Iteration: 3440 Validation loss: 0.225688 Validation acc: 0.935556\n",
      "Epoch: 382/500 Iteration: 3445 Train loss: 0.041393 Train acc: 0.986667\n",
      "Epoch: 383/500 Iteration: 3450 Train loss: 0.046596 Train acc: 0.988333\n",
      "Epoch: 383/500 Iteration: 3450 Validation loss: 0.225084 Validation acc: 0.933889\n",
      "Epoch: 383/500 Iteration: 3455 Train loss: 0.030070 Train acc: 0.993333\n",
      "Epoch: 384/500 Iteration: 3460 Train loss: 0.047308 Train acc: 0.986667\n",
      "Epoch: 384/500 Iteration: 3460 Validation loss: 0.235155 Validation acc: 0.933333\n",
      "Epoch: 384/500 Iteration: 3465 Train loss: 0.051758 Train acc: 0.981667\n",
      "Epoch: 385/500 Iteration: 3470 Train loss: 0.041925 Train acc: 0.983333\n",
      "Epoch: 385/500 Iteration: 3470 Validation loss: 0.237017 Validation acc: 0.935000\n",
      "Epoch: 386/500 Iteration: 3475 Train loss: 0.040276 Train acc: 0.988333\n",
      "Epoch: 386/500 Iteration: 3480 Train loss: 0.065385 Train acc: 0.975000\n",
      "Epoch: 386/500 Iteration: 3480 Validation loss: 0.231171 Validation acc: 0.935000\n",
      "Epoch: 387/500 Iteration: 3485 Train loss: 0.041219 Train acc: 0.985000\n",
      "Epoch: 387/500 Iteration: 3490 Train loss: 0.027034 Train acc: 0.988333\n",
      "Epoch: 387/500 Iteration: 3490 Validation loss: 0.229406 Validation acc: 0.938333\n",
      "Epoch: 388/500 Iteration: 3495 Train loss: 0.039078 Train acc: 0.985000\n",
      "Epoch: 388/500 Iteration: 3500 Train loss: 0.043940 Train acc: 0.981667\n",
      "Epoch: 388/500 Iteration: 3500 Validation loss: 0.236418 Validation acc: 0.935556\n",
      "Epoch: 389/500 Iteration: 3505 Train loss: 0.043918 Train acc: 0.978333\n",
      "Epoch: 389/500 Iteration: 3510 Train loss: 0.020961 Train acc: 0.995000\n",
      "Epoch: 389/500 Iteration: 3510 Validation loss: 0.232534 Validation acc: 0.935556\n",
      "Epoch: 390/500 Iteration: 3515 Train loss: 0.035515 Train acc: 0.986667\n",
      "Epoch: 391/500 Iteration: 3520 Train loss: 0.034057 Train acc: 0.985000\n",
      "Epoch: 391/500 Iteration: 3520 Validation loss: 0.233045 Validation acc: 0.937222\n",
      "Epoch: 391/500 Iteration: 3525 Train loss: 0.037900 Train acc: 0.985000\n",
      "Epoch: 392/500 Iteration: 3530 Train loss: 0.023522 Train acc: 0.995000\n",
      "Epoch: 392/500 Iteration: 3530 Validation loss: 0.228326 Validation acc: 0.935000\n",
      "Epoch: 392/500 Iteration: 3535 Train loss: 0.049554 Train acc: 0.981667\n",
      "Epoch: 393/500 Iteration: 3540 Train loss: 0.041832 Train acc: 0.983333\n",
      "Epoch: 393/500 Iteration: 3540 Validation loss: 0.230548 Validation acc: 0.933333\n",
      "Epoch: 393/500 Iteration: 3545 Train loss: 0.035906 Train acc: 0.985000\n",
      "Epoch: 394/500 Iteration: 3550 Train loss: 0.023402 Train acc: 0.995000\n",
      "Epoch: 394/500 Iteration: 3550 Validation loss: 0.233177 Validation acc: 0.935556\n",
      "Epoch: 394/500 Iteration: 3555 Train loss: 0.035802 Train acc: 0.985000\n",
      "Epoch: 395/500 Iteration: 3560 Train loss: 0.048302 Train acc: 0.981667\n",
      "Epoch: 395/500 Iteration: 3560 Validation loss: 0.228762 Validation acc: 0.936111\n",
      "Epoch: 396/500 Iteration: 3565 Train loss: 0.045971 Train acc: 0.978333\n",
      "Epoch: 396/500 Iteration: 3570 Train loss: 0.040928 Train acc: 0.983333\n",
      "Epoch: 396/500 Iteration: 3570 Validation loss: 0.230046 Validation acc: 0.932222\n",
      "Epoch: 397/500 Iteration: 3575 Train loss: 0.038226 Train acc: 0.988333\n",
      "Epoch: 397/500 Iteration: 3580 Train loss: 0.051762 Train acc: 0.980000\n",
      "Epoch: 397/500 Iteration: 3580 Validation loss: 0.235849 Validation acc: 0.936111\n",
      "Epoch: 398/500 Iteration: 3585 Train loss: 0.038177 Train acc: 0.986667\n",
      "Epoch: 398/500 Iteration: 3590 Train loss: 0.044104 Train acc: 0.980000\n",
      "Epoch: 398/500 Iteration: 3590 Validation loss: 0.227627 Validation acc: 0.935556\n",
      "Epoch: 399/500 Iteration: 3595 Train loss: 0.032616 Train acc: 0.990000\n",
      "Epoch: 399/500 Iteration: 3600 Train loss: 0.027924 Train acc: 0.991667\n",
      "Epoch: 399/500 Iteration: 3600 Validation loss: 0.228455 Validation acc: 0.934444\n",
      "Epoch: 400/500 Iteration: 3605 Train loss: 0.041767 Train acc: 0.991667\n",
      "Epoch: 401/500 Iteration: 3610 Train loss: 0.038760 Train acc: 0.986667\n",
      "Epoch: 401/500 Iteration: 3610 Validation loss: 0.229307 Validation acc: 0.933333\n",
      "Epoch: 401/500 Iteration: 3615 Train loss: 0.046128 Train acc: 0.983333\n",
      "Epoch: 402/500 Iteration: 3620 Train loss: 0.048139 Train acc: 0.983333\n",
      "Epoch: 402/500 Iteration: 3620 Validation loss: 0.226097 Validation acc: 0.934444\n",
      "Epoch: 402/500 Iteration: 3625 Train loss: 0.054032 Train acc: 0.976667\n",
      "Epoch: 403/500 Iteration: 3630 Train loss: 0.042037 Train acc: 0.986667\n",
      "Epoch: 403/500 Iteration: 3630 Validation loss: 0.231950 Validation acc: 0.935000\n",
      "Epoch: 403/500 Iteration: 3635 Train loss: 0.051906 Train acc: 0.983333\n",
      "Epoch: 404/500 Iteration: 3640 Train loss: 0.044280 Train acc: 0.975000\n",
      "Epoch: 404/500 Iteration: 3640 Validation loss: 0.220760 Validation acc: 0.936667\n",
      "Epoch: 404/500 Iteration: 3645 Train loss: 0.043359 Train acc: 0.988333\n",
      "Epoch: 405/500 Iteration: 3650 Train loss: 0.040649 Train acc: 0.988333\n",
      "Epoch: 405/500 Iteration: 3650 Validation loss: 0.228934 Validation acc: 0.937222\n",
      "Epoch: 406/500 Iteration: 3655 Train loss: 0.052106 Train acc: 0.983333\n",
      "Epoch: 406/500 Iteration: 3660 Train loss: 0.042523 Train acc: 0.988333\n",
      "Epoch: 406/500 Iteration: 3660 Validation loss: 0.234309 Validation acc: 0.935555\n",
      "Epoch: 407/500 Iteration: 3665 Train loss: 0.034931 Train acc: 0.988333\n",
      "Epoch: 407/500 Iteration: 3670 Train loss: 0.047016 Train acc: 0.986667\n",
      "Epoch: 407/500 Iteration: 3670 Validation loss: 0.233735 Validation acc: 0.936667\n",
      "Epoch: 408/500 Iteration: 3675 Train loss: 0.042143 Train acc: 0.983333\n",
      "Epoch: 408/500 Iteration: 3680 Train loss: 0.042539 Train acc: 0.981667\n",
      "Epoch: 408/500 Iteration: 3680 Validation loss: 0.233614 Validation acc: 0.934444\n",
      "Epoch: 409/500 Iteration: 3685 Train loss: 0.023846 Train acc: 0.990000\n",
      "Epoch: 409/500 Iteration: 3690 Train loss: 0.036314 Train acc: 0.983333\n",
      "Epoch: 409/500 Iteration: 3690 Validation loss: 0.227203 Validation acc: 0.931667\n",
      "Epoch: 410/500 Iteration: 3695 Train loss: 0.049538 Train acc: 0.981667\n",
      "Epoch: 411/500 Iteration: 3700 Train loss: 0.046483 Train acc: 0.988333\n",
      "Epoch: 411/500 Iteration: 3700 Validation loss: 0.226483 Validation acc: 0.935555\n",
      "Epoch: 411/500 Iteration: 3705 Train loss: 0.044208 Train acc: 0.991667\n",
      "Epoch: 412/500 Iteration: 3710 Train loss: 0.038616 Train acc: 0.986667\n",
      "Epoch: 412/500 Iteration: 3710 Validation loss: 0.236476 Validation acc: 0.933889\n",
      "Epoch: 412/500 Iteration: 3715 Train loss: 0.038287 Train acc: 0.986667\n",
      "Epoch: 413/500 Iteration: 3720 Train loss: 0.048953 Train acc: 0.985000\n",
      "Epoch: 413/500 Iteration: 3720 Validation loss: 0.245563 Validation acc: 0.932222\n",
      "Epoch: 413/500 Iteration: 3725 Train loss: 0.033304 Train acc: 0.990000\n",
      "Epoch: 414/500 Iteration: 3730 Train loss: 0.037220 Train acc: 0.986667\n",
      "Epoch: 414/500 Iteration: 3730 Validation loss: 0.243194 Validation acc: 0.936111\n",
      "Epoch: 414/500 Iteration: 3735 Train loss: 0.032466 Train acc: 0.988333\n",
      "Epoch: 415/500 Iteration: 3740 Train loss: 0.030586 Train acc: 0.991667\n",
      "Epoch: 415/500 Iteration: 3740 Validation loss: 0.237489 Validation acc: 0.935556\n",
      "Epoch: 416/500 Iteration: 3745 Train loss: 0.024128 Train acc: 0.993333\n",
      "Epoch: 416/500 Iteration: 3750 Train loss: 0.049613 Train acc: 0.985000\n",
      "Epoch: 416/500 Iteration: 3750 Validation loss: 0.234136 Validation acc: 0.936111\n",
      "Epoch: 417/500 Iteration: 3755 Train loss: 0.031709 Train acc: 0.985000\n",
      "Epoch: 417/500 Iteration: 3760 Train loss: 0.021047 Train acc: 0.995000\n",
      "Epoch: 417/500 Iteration: 3760 Validation loss: 0.241774 Validation acc: 0.936111\n",
      "Epoch: 418/500 Iteration: 3765 Train loss: 0.032929 Train acc: 0.988333\n",
      "Epoch: 418/500 Iteration: 3770 Train loss: 0.049973 Train acc: 0.980000\n",
      "Epoch: 418/500 Iteration: 3770 Validation loss: 0.238526 Validation acc: 0.933889\n",
      "Epoch: 419/500 Iteration: 3775 Train loss: 0.057768 Train acc: 0.973333\n",
      "Epoch: 419/500 Iteration: 3780 Train loss: 0.050897 Train acc: 0.981667\n",
      "Epoch: 419/500 Iteration: 3780 Validation loss: 0.244294 Validation acc: 0.932778\n",
      "Epoch: 420/500 Iteration: 3785 Train loss: 0.024857 Train acc: 0.991667\n",
      "Epoch: 421/500 Iteration: 3790 Train loss: 0.036604 Train acc: 0.985000\n",
      "Epoch: 421/500 Iteration: 3790 Validation loss: 0.240342 Validation acc: 0.936667\n",
      "Epoch: 421/500 Iteration: 3795 Train loss: 0.047450 Train acc: 0.981667\n",
      "Epoch: 422/500 Iteration: 3800 Train loss: 0.034027 Train acc: 0.988333\n",
      "Epoch: 422/500 Iteration: 3800 Validation loss: 0.237118 Validation acc: 0.931667\n",
      "Epoch: 422/500 Iteration: 3805 Train loss: 0.048559 Train acc: 0.980000\n",
      "Epoch: 423/500 Iteration: 3810 Train loss: 0.038112 Train acc: 0.988333\n",
      "Epoch: 423/500 Iteration: 3810 Validation loss: 0.232582 Validation acc: 0.936111\n",
      "Epoch: 423/500 Iteration: 3815 Train loss: 0.040268 Train acc: 0.981667\n",
      "Epoch: 424/500 Iteration: 3820 Train loss: 0.037462 Train acc: 0.985000\n",
      "Epoch: 424/500 Iteration: 3820 Validation loss: 0.237048 Validation acc: 0.933889\n",
      "Epoch: 424/500 Iteration: 3825 Train loss: 0.051326 Train acc: 0.980000\n",
      "Epoch: 425/500 Iteration: 3830 Train loss: 0.031704 Train acc: 0.991667\n",
      "Epoch: 425/500 Iteration: 3830 Validation loss: 0.232800 Validation acc: 0.932778\n",
      "Epoch: 426/500 Iteration: 3835 Train loss: 0.033859 Train acc: 0.991667\n",
      "Epoch: 426/500 Iteration: 3840 Train loss: 0.039458 Train acc: 0.986667\n",
      "Epoch: 426/500 Iteration: 3840 Validation loss: 0.243765 Validation acc: 0.935556\n",
      "Epoch: 427/500 Iteration: 3845 Train loss: 0.042938 Train acc: 0.985000\n",
      "Epoch: 427/500 Iteration: 3850 Train loss: 0.026372 Train acc: 0.993333\n",
      "Epoch: 427/500 Iteration: 3850 Validation loss: 0.243540 Validation acc: 0.936667\n",
      "Epoch: 428/500 Iteration: 3855 Train loss: 0.028307 Train acc: 0.990000\n",
      "Epoch: 428/500 Iteration: 3860 Train loss: 0.043136 Train acc: 0.978333\n",
      "Epoch: 428/500 Iteration: 3860 Validation loss: 0.242689 Validation acc: 0.935000\n",
      "Epoch: 429/500 Iteration: 3865 Train loss: 0.041179 Train acc: 0.981667\n",
      "Epoch: 429/500 Iteration: 3870 Train loss: 0.046380 Train acc: 0.986667\n",
      "Epoch: 429/500 Iteration: 3870 Validation loss: 0.236502 Validation acc: 0.936667\n",
      "Epoch: 430/500 Iteration: 3875 Train loss: 0.052309 Train acc: 0.981667\n",
      "Epoch: 431/500 Iteration: 3880 Train loss: 0.039212 Train acc: 0.988333\n",
      "Epoch: 431/500 Iteration: 3880 Validation loss: 0.235904 Validation acc: 0.936667\n",
      "Epoch: 431/500 Iteration: 3885 Train loss: 0.039945 Train acc: 0.986667\n",
      "Epoch: 432/500 Iteration: 3890 Train loss: 0.024085 Train acc: 0.993333\n",
      "Epoch: 432/500 Iteration: 3890 Validation loss: 0.245625 Validation acc: 0.937222\n",
      "Epoch: 432/500 Iteration: 3895 Train loss: 0.061098 Train acc: 0.973333\n",
      "Epoch: 433/500 Iteration: 3900 Train loss: 0.032156 Train acc: 0.990000\n",
      "Epoch: 433/500 Iteration: 3900 Validation loss: 0.239951 Validation acc: 0.933333\n",
      "Epoch: 433/500 Iteration: 3905 Train loss: 0.025198 Train acc: 0.993333\n",
      "Epoch: 434/500 Iteration: 3910 Train loss: 0.029005 Train acc: 0.993333\n",
      "Epoch: 434/500 Iteration: 3910 Validation loss: 0.232137 Validation acc: 0.935000\n",
      "Epoch: 434/500 Iteration: 3915 Train loss: 0.025703 Train acc: 0.988333\n",
      "Epoch: 435/500 Iteration: 3920 Train loss: 0.031326 Train acc: 0.990000\n",
      "Epoch: 435/500 Iteration: 3920 Validation loss: 0.232294 Validation acc: 0.937222\n",
      "Epoch: 436/500 Iteration: 3925 Train loss: 0.044937 Train acc: 0.983333\n",
      "Epoch: 436/500 Iteration: 3930 Train loss: 0.032752 Train acc: 0.986667\n",
      "Epoch: 436/500 Iteration: 3930 Validation loss: 0.231072 Validation acc: 0.936667\n",
      "Epoch: 437/500 Iteration: 3935 Train loss: 0.031619 Train acc: 0.990000\n",
      "Epoch: 437/500 Iteration: 3940 Train loss: 0.051634 Train acc: 0.985000\n",
      "Epoch: 437/500 Iteration: 3940 Validation loss: 0.232167 Validation acc: 0.938333\n",
      "Epoch: 438/500 Iteration: 3945 Train loss: 0.035952 Train acc: 0.990000\n",
      "Epoch: 438/500 Iteration: 3950 Train loss: 0.038352 Train acc: 0.986667\n",
      "Epoch: 438/500 Iteration: 3950 Validation loss: 0.231221 Validation acc: 0.932222\n",
      "Epoch: 439/500 Iteration: 3955 Train loss: 0.034180 Train acc: 0.990000\n",
      "Epoch: 439/500 Iteration: 3960 Train loss: 0.030100 Train acc: 0.985000\n",
      "Epoch: 439/500 Iteration: 3960 Validation loss: 0.243352 Validation acc: 0.933333\n",
      "Epoch: 440/500 Iteration: 3965 Train loss: 0.041352 Train acc: 0.981667\n",
      "Epoch: 441/500 Iteration: 3970 Train loss: 0.036868 Train acc: 0.995000\n",
      "Epoch: 441/500 Iteration: 3970 Validation loss: 0.234395 Validation acc: 0.936111\n",
      "Epoch: 441/500 Iteration: 3975 Train loss: 0.045625 Train acc: 0.985000\n",
      "Epoch: 442/500 Iteration: 3980 Train loss: 0.033075 Train acc: 0.991667\n",
      "Epoch: 442/500 Iteration: 3980 Validation loss: 0.245243 Validation acc: 0.937222\n",
      "Epoch: 442/500 Iteration: 3985 Train loss: 0.031058 Train acc: 0.990000\n",
      "Epoch: 443/500 Iteration: 3990 Train loss: 0.048129 Train acc: 0.985000\n",
      "Epoch: 443/500 Iteration: 3990 Validation loss: 0.248780 Validation acc: 0.937222\n",
      "Epoch: 443/500 Iteration: 3995 Train loss: 0.039960 Train acc: 0.980000\n",
      "Epoch: 444/500 Iteration: 4000 Train loss: 0.033320 Train acc: 0.988333\n",
      "Epoch: 444/500 Iteration: 4000 Validation loss: 0.239693 Validation acc: 0.940556\n",
      "Epoch: 444/500 Iteration: 4005 Train loss: 0.023122 Train acc: 0.991667\n",
      "Epoch: 445/500 Iteration: 4010 Train loss: 0.046875 Train acc: 0.980000\n",
      "Epoch: 445/500 Iteration: 4010 Validation loss: 0.234352 Validation acc: 0.936667\n",
      "Epoch: 446/500 Iteration: 4015 Train loss: 0.054991 Train acc: 0.978333\n",
      "Epoch: 446/500 Iteration: 4020 Train loss: 0.047669 Train acc: 0.988333\n",
      "Epoch: 446/500 Iteration: 4020 Validation loss: 0.238184 Validation acc: 0.935000\n",
      "Epoch: 447/500 Iteration: 4025 Train loss: 0.030990 Train acc: 0.990000\n",
      "Epoch: 447/500 Iteration: 4030 Train loss: 0.042641 Train acc: 0.981667\n",
      "Epoch: 447/500 Iteration: 4030 Validation loss: 0.234690 Validation acc: 0.936111\n",
      "Epoch: 448/500 Iteration: 4035 Train loss: 0.039848 Train acc: 0.983333\n",
      "Epoch: 448/500 Iteration: 4040 Train loss: 0.037692 Train acc: 0.981667\n",
      "Epoch: 448/500 Iteration: 4040 Validation loss: 0.240483 Validation acc: 0.933333\n",
      "Epoch: 449/500 Iteration: 4045 Train loss: 0.029851 Train acc: 0.993333\n",
      "Epoch: 449/500 Iteration: 4050 Train loss: 0.030736 Train acc: 0.991667\n",
      "Epoch: 449/500 Iteration: 4050 Validation loss: 0.242080 Validation acc: 0.933889\n",
      "Epoch: 450/500 Iteration: 4055 Train loss: 0.025191 Train acc: 0.991667\n",
      "Epoch: 451/500 Iteration: 4060 Train loss: 0.035526 Train acc: 0.985000\n",
      "Epoch: 451/500 Iteration: 4060 Validation loss: 0.236745 Validation acc: 0.933333\n",
      "Epoch: 451/500 Iteration: 4065 Train loss: 0.048998 Train acc: 0.981667\n",
      "Epoch: 452/500 Iteration: 4070 Train loss: 0.037603 Train acc: 0.986667\n",
      "Epoch: 452/500 Iteration: 4070 Validation loss: 0.231612 Validation acc: 0.936667\n",
      "Epoch: 452/500 Iteration: 4075 Train loss: 0.028931 Train acc: 0.988333\n",
      "Epoch: 453/500 Iteration: 4080 Train loss: 0.027344 Train acc: 0.991667\n",
      "Epoch: 453/500 Iteration: 4080 Validation loss: 0.235567 Validation acc: 0.938889\n",
      "Epoch: 453/500 Iteration: 4085 Train loss: 0.024950 Train acc: 0.990000\n",
      "Epoch: 454/500 Iteration: 4090 Train loss: 0.039196 Train acc: 0.985000\n",
      "Epoch: 454/500 Iteration: 4090 Validation loss: 0.233316 Validation acc: 0.937222\n",
      "Epoch: 454/500 Iteration: 4095 Train loss: 0.036939 Train acc: 0.988333\n",
      "Epoch: 455/500 Iteration: 4100 Train loss: 0.027843 Train acc: 0.996667\n",
      "Epoch: 455/500 Iteration: 4100 Validation loss: 0.236311 Validation acc: 0.938333\n",
      "Epoch: 456/500 Iteration: 4105 Train loss: 0.019130 Train acc: 0.995000\n",
      "Epoch: 456/500 Iteration: 4110 Train loss: 0.046629 Train acc: 0.985000\n",
      "Epoch: 456/500 Iteration: 4110 Validation loss: 0.242672 Validation acc: 0.940000\n",
      "Epoch: 457/500 Iteration: 4115 Train loss: 0.037532 Train acc: 0.985000\n",
      "Epoch: 457/500 Iteration: 4120 Train loss: 0.034448 Train acc: 0.988333\n",
      "Epoch: 457/500 Iteration: 4120 Validation loss: 0.240779 Validation acc: 0.938889\n",
      "Epoch: 458/500 Iteration: 4125 Train loss: 0.032194 Train acc: 0.991667\n",
      "Epoch: 458/500 Iteration: 4130 Train loss: 0.026258 Train acc: 0.991667\n",
      "Epoch: 458/500 Iteration: 4130 Validation loss: 0.247198 Validation acc: 0.938333\n",
      "Epoch: 459/500 Iteration: 4135 Train loss: 0.033796 Train acc: 0.986667\n",
      "Epoch: 459/500 Iteration: 4140 Train loss: 0.027672 Train acc: 0.991667\n",
      "Epoch: 459/500 Iteration: 4140 Validation loss: 0.243386 Validation acc: 0.936667\n",
      "Epoch: 460/500 Iteration: 4145 Train loss: 0.016318 Train acc: 0.996667\n",
      "Epoch: 461/500 Iteration: 4150 Train loss: 0.022312 Train acc: 0.991667\n",
      "Epoch: 461/500 Iteration: 4150 Validation loss: 0.243040 Validation acc: 0.936111\n",
      "Epoch: 461/500 Iteration: 4155 Train loss: 0.028108 Train acc: 0.993333\n",
      "Epoch: 462/500 Iteration: 4160 Train loss: 0.042960 Train acc: 0.983333\n",
      "Epoch: 462/500 Iteration: 4160 Validation loss: 0.236501 Validation acc: 0.936667\n",
      "Epoch: 462/500 Iteration: 4165 Train loss: 0.027952 Train acc: 0.991667\n",
      "Epoch: 463/500 Iteration: 4170 Train loss: 0.024465 Train acc: 0.995000\n",
      "Epoch: 463/500 Iteration: 4170 Validation loss: 0.236337 Validation acc: 0.937778\n",
      "Epoch: 463/500 Iteration: 4175 Train loss: 0.027039 Train acc: 0.995000\n",
      "Epoch: 464/500 Iteration: 4180 Train loss: 0.034079 Train acc: 0.990000\n",
      "Epoch: 464/500 Iteration: 4180 Validation loss: 0.245548 Validation acc: 0.938333\n",
      "Epoch: 464/500 Iteration: 4185 Train loss: 0.030607 Train acc: 0.988333\n",
      "Epoch: 465/500 Iteration: 4190 Train loss: 0.037388 Train acc: 0.986667\n",
      "Epoch: 465/500 Iteration: 4190 Validation loss: 0.245254 Validation acc: 0.934444\n",
      "Epoch: 466/500 Iteration: 4195 Train loss: 0.035157 Train acc: 0.981667\n",
      "Epoch: 466/500 Iteration: 4200 Train loss: 0.021874 Train acc: 0.993333\n",
      "Epoch: 466/500 Iteration: 4200 Validation loss: 0.239707 Validation acc: 0.936667\n",
      "Epoch: 467/500 Iteration: 4205 Train loss: 0.016403 Train acc: 0.995000\n",
      "Epoch: 467/500 Iteration: 4210 Train loss: 0.027019 Train acc: 0.990000\n",
      "Epoch: 467/500 Iteration: 4210 Validation loss: 0.233651 Validation acc: 0.936667\n",
      "Epoch: 468/500 Iteration: 4215 Train loss: 0.033059 Train acc: 0.988333\n",
      "Epoch: 468/500 Iteration: 4220 Train loss: 0.018114 Train acc: 0.996667\n",
      "Epoch: 468/500 Iteration: 4220 Validation loss: 0.238739 Validation acc: 0.932778\n",
      "Epoch: 469/500 Iteration: 4225 Train loss: 0.021850 Train acc: 0.998333\n",
      "Epoch: 469/500 Iteration: 4230 Train loss: 0.024303 Train acc: 0.991667\n",
      "Epoch: 469/500 Iteration: 4230 Validation loss: 0.240655 Validation acc: 0.933333\n",
      "Epoch: 470/500 Iteration: 4235 Train loss: 0.027063 Train acc: 0.993333\n",
      "Epoch: 471/500 Iteration: 4240 Train loss: 0.036678 Train acc: 0.985000\n",
      "Epoch: 471/500 Iteration: 4240 Validation loss: 0.234945 Validation acc: 0.936667\n",
      "Epoch: 471/500 Iteration: 4245 Train loss: 0.040387 Train acc: 0.988333\n",
      "Epoch: 472/500 Iteration: 4250 Train loss: 0.036350 Train acc: 0.988333\n",
      "Epoch: 472/500 Iteration: 4250 Validation loss: 0.243240 Validation acc: 0.937222\n",
      "Epoch: 472/500 Iteration: 4255 Train loss: 0.029996 Train acc: 0.986667\n",
      "Epoch: 473/500 Iteration: 4260 Train loss: 0.024282 Train acc: 0.995000\n",
      "Epoch: 473/500 Iteration: 4260 Validation loss: 0.248703 Validation acc: 0.938333\n",
      "Epoch: 473/500 Iteration: 4265 Train loss: 0.018696 Train acc: 0.995000\n",
      "Epoch: 474/500 Iteration: 4270 Train loss: 0.023489 Train acc: 0.990000\n",
      "Epoch: 474/500 Iteration: 4270 Validation loss: 0.245722 Validation acc: 0.936667\n",
      "Epoch: 474/500 Iteration: 4275 Train loss: 0.037526 Train acc: 0.988333\n",
      "Epoch: 475/500 Iteration: 4280 Train loss: 0.035833 Train acc: 0.991667\n",
      "Epoch: 475/500 Iteration: 4280 Validation loss: 0.237559 Validation acc: 0.937222\n",
      "Epoch: 476/500 Iteration: 4285 Train loss: 0.039942 Train acc: 0.986667\n",
      "Epoch: 476/500 Iteration: 4290 Train loss: 0.051637 Train acc: 0.981667\n",
      "Epoch: 476/500 Iteration: 4290 Validation loss: 0.234772 Validation acc: 0.938333\n",
      "Epoch: 477/500 Iteration: 4295 Train loss: 0.026254 Train acc: 0.990000\n",
      "Epoch: 477/500 Iteration: 4300 Train loss: 0.047553 Train acc: 0.983333\n",
      "Epoch: 477/500 Iteration: 4300 Validation loss: 0.240314 Validation acc: 0.935555\n",
      "Epoch: 478/500 Iteration: 4305 Train loss: 0.030096 Train acc: 0.993333\n",
      "Epoch: 478/500 Iteration: 4310 Train loss: 0.035941 Train acc: 0.988333\n",
      "Epoch: 478/500 Iteration: 4310 Validation loss: 0.244068 Validation acc: 0.932778\n",
      "Epoch: 479/500 Iteration: 4315 Train loss: 0.031525 Train acc: 0.988333\n",
      "Epoch: 479/500 Iteration: 4320 Train loss: 0.032683 Train acc: 0.986667\n",
      "Epoch: 479/500 Iteration: 4320 Validation loss: 0.243167 Validation acc: 0.933889\n",
      "Epoch: 480/500 Iteration: 4325 Train loss: 0.054861 Train acc: 0.983333\n",
      "Epoch: 481/500 Iteration: 4330 Train loss: 0.022067 Train acc: 0.996667\n",
      "Epoch: 481/500 Iteration: 4330 Validation loss: 0.243076 Validation acc: 0.935556\n",
      "Epoch: 481/500 Iteration: 4335 Train loss: 0.024955 Train acc: 0.993333\n",
      "Epoch: 482/500 Iteration: 4340 Train loss: 0.023796 Train acc: 0.993333\n",
      "Epoch: 482/500 Iteration: 4340 Validation loss: 0.237433 Validation acc: 0.935000\n",
      "Epoch: 482/500 Iteration: 4345 Train loss: 0.042121 Train acc: 0.980000\n",
      "Epoch: 483/500 Iteration: 4350 Train loss: 0.032091 Train acc: 0.988333\n",
      "Epoch: 483/500 Iteration: 4350 Validation loss: 0.242160 Validation acc: 0.937778\n",
      "Epoch: 483/500 Iteration: 4355 Train loss: 0.034331 Train acc: 0.985000\n",
      "Epoch: 484/500 Iteration: 4360 Train loss: 0.028354 Train acc: 0.988333\n",
      "Epoch: 484/500 Iteration: 4360 Validation loss: 0.242335 Validation acc: 0.935555\n",
      "Epoch: 484/500 Iteration: 4365 Train loss: 0.029854 Train acc: 0.988333\n",
      "Epoch: 485/500 Iteration: 4370 Train loss: 0.046122 Train acc: 0.978333\n",
      "Epoch: 485/500 Iteration: 4370 Validation loss: 0.252785 Validation acc: 0.932222\n",
      "Epoch: 486/500 Iteration: 4375 Train loss: 0.038850 Train acc: 0.985000\n",
      "Epoch: 486/500 Iteration: 4380 Train loss: 0.029957 Train acc: 0.991667\n",
      "Epoch: 486/500 Iteration: 4380 Validation loss: 0.248550 Validation acc: 0.934444\n",
      "Epoch: 487/500 Iteration: 4385 Train loss: 0.024366 Train acc: 0.986667\n",
      "Epoch: 487/500 Iteration: 4390 Train loss: 0.018771 Train acc: 0.993333\n",
      "Epoch: 487/500 Iteration: 4390 Validation loss: 0.254668 Validation acc: 0.933889\n",
      "Epoch: 488/500 Iteration: 4395 Train loss: 0.028646 Train acc: 0.991667\n",
      "Epoch: 488/500 Iteration: 4400 Train loss: 0.027450 Train acc: 0.995000\n",
      "Epoch: 488/500 Iteration: 4400 Validation loss: 0.260515 Validation acc: 0.935555\n",
      "Epoch: 489/500 Iteration: 4405 Train loss: 0.026913 Train acc: 0.993333\n",
      "Epoch: 489/500 Iteration: 4410 Train loss: 0.030803 Train acc: 0.990000\n",
      "Epoch: 489/500 Iteration: 4410 Validation loss: 0.247869 Validation acc: 0.936667\n",
      "Epoch: 490/500 Iteration: 4415 Train loss: 0.029390 Train acc: 0.991667\n",
      "Epoch: 491/500 Iteration: 4420 Train loss: 0.024668 Train acc: 0.993333\n",
      "Epoch: 491/500 Iteration: 4420 Validation loss: 0.237075 Validation acc: 0.937778\n",
      "Epoch: 491/500 Iteration: 4425 Train loss: 0.047600 Train acc: 0.986667\n",
      "Epoch: 492/500 Iteration: 4430 Train loss: 0.017740 Train acc: 0.993333\n",
      "Epoch: 492/500 Iteration: 4430 Validation loss: 0.236301 Validation acc: 0.936667\n",
      "Epoch: 492/500 Iteration: 4435 Train loss: 0.035087 Train acc: 0.990000\n",
      "Epoch: 493/500 Iteration: 4440 Train loss: 0.033377 Train acc: 0.981667\n",
      "Epoch: 493/500 Iteration: 4440 Validation loss: 0.242554 Validation acc: 0.940000\n",
      "Epoch: 493/500 Iteration: 4445 Train loss: 0.033210 Train acc: 0.988333\n",
      "Epoch: 494/500 Iteration: 4450 Train loss: 0.022191 Train acc: 0.996667\n",
      "Epoch: 494/500 Iteration: 4450 Validation loss: 0.239267 Validation acc: 0.937222\n",
      "Epoch: 494/500 Iteration: 4455 Train loss: 0.021704 Train acc: 0.991667\n",
      "Epoch: 495/500 Iteration: 4460 Train loss: 0.038870 Train acc: 0.980000\n",
      "Epoch: 495/500 Iteration: 4460 Validation loss: 0.240055 Validation acc: 0.936667\n",
      "Epoch: 496/500 Iteration: 4465 Train loss: 0.029583 Train acc: 0.988333\n",
      "Epoch: 496/500 Iteration: 4470 Train loss: 0.035607 Train acc: 0.985000\n",
      "Epoch: 496/500 Iteration: 4470 Validation loss: 0.246069 Validation acc: 0.935555\n",
      "Epoch: 497/500 Iteration: 4475 Train loss: 0.025001 Train acc: 0.991667\n",
      "Epoch: 497/500 Iteration: 4480 Train loss: 0.026663 Train acc: 0.993333\n",
      "Epoch: 497/500 Iteration: 4480 Validation loss: 0.245680 Validation acc: 0.934444\n",
      "Epoch: 498/500 Iteration: 4485 Train loss: 0.018325 Train acc: 0.995000\n",
      "Epoch: 498/500 Iteration: 4490 Train loss: 0.031188 Train acc: 0.990000\n",
      "Epoch: 498/500 Iteration: 4490 Validation loss: 0.253418 Validation acc: 0.935556\n",
      "Epoch: 499/500 Iteration: 4495 Train loss: 0.020909 Train acc: 0.995000\n",
      "Epoch: 499/500 Iteration: 4500 Train loss: 0.034118 Train acc: 0.988333\n",
      "Epoch: 499/500 Iteration: 4500 Validation loss: 0.279357 Validation acc: 0.934444\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa74b98aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhQUREQkSUFBRESSFBRERCTp/wNNFtqy/3lH5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7347ba4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.981667\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
