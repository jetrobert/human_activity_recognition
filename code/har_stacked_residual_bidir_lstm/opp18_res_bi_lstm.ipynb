{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm_architecture import one_hot, run_with_config\n",
    "from sliding_window import sliding_window\n",
    "import numpy as np\n",
    "import cPickle as cp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net's config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    define a class to store parameters,\n",
    "    the input should be feature mat of training and testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test):\n",
    "        # Data shaping\n",
    "        self.train_count = len(X_train)  # nb of training series\n",
    "        self.test_data_count = len(X_test)  # nb of testing series\n",
    "        self.n_steps = len(X_train[0])  # nb of time_steps per series\n",
    "        self.n_classes = 18  # Final output classes, one classification per series\n",
    "\n",
    "        # Training\n",
    "        self.learning_rate = 0.001\n",
    "        self.lambda_loss_amount = 0.005\n",
    "        self.training_epochs = 100\n",
    "        self.batch_size = 100\n",
    "        self.clip_gradients = 15.0\n",
    "        self.gradient_noise_scale = None\n",
    "        self.keep_prob_for_dropout = 0.85  # **(1/3.0)  # Dropout is added on inputs and after each stacked layers (but not between residual layers).\n",
    "\n",
    "        # Linear+relu structure\n",
    "        self.bias_mean = 0.3\n",
    "        self.weights_stddev = 0.2  # I would recommend between 0.1 and 1.0 or to change and use a xavier initializer\n",
    "\n",
    "        ########\n",
    "        # NOTE: I think that if any of the below parameters are changed,\n",
    "        # the best is to readjust every parameters in the \"Training\" section\n",
    "        # above to properly compare the architectures only once optimised.\n",
    "        ########\n",
    "\n",
    "        # LSTM structure\n",
    "        self.n_inputs = len(X_train[0][0])  # Features count\n",
    "        self.n_hidden = 28  # nb of neurons inside the neural network\n",
    "        self.use_bidirectionnal_cells = True  # Use bidir in every LSTM cell, or not:\n",
    "\n",
    "        # High-level deep architecture\n",
    "        self.also_add_dropout_between_stacked_cells = False  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset-specific constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "NB_SENSOR_CHANNELS_WITH_FILTERING = 149\n",
    "\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "NUM_CLASSES = 18\n",
    "\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Length of the input sequence after convolutional operations\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_STEP = int(SLIDING_WINDOW_LENGTH/2)\n",
    "SLIDING_WINDOW_STEP_SHORT = SLIDING_WINDOW_STEP\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Number filters convolutional layers\n",
    "NUM_FILTERS = 64\n",
    "\n",
    "# Size filters convolutional layers\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "# Number of unit in the long short-term recurrent layers\n",
    "NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset and set sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      "after sliding window (testing): inputs (118750, 113), targets (118750,)\n",
      "after sliding window (testing): inputs (9894, 24, 113), targets (9894, 18)\n",
      "(46495, 24, 113)\n",
      "(46495, 18)\n",
      "(9894, 24, 113)\n",
      "(9894, 18)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = file(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
    "\n",
    "assert (NB_SENSOR_CHANNELS_WITH_FILTERING == \\\n",
    "        X_train.shape[1] or NB_SENSOR_CHANNELS == X_train.shape[1])\n",
    "\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    data_x, data_y = data_x.astype(np.float32), \\\n",
    "    one_hot(data_y.reshape(len(data_y)).astype(np.uint8))\n",
    "    print(\"after sliding window (testing): inputs {0}, targets {1}\"\\\n",
    "          .format(X_test.shape, y_test.shape))\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# Loading dataset\n",
    "#--------------------------------------------\n",
    "\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, \n",
    "                        SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP_SHORT)\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, \n",
    "                            SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "for mat in [X_train, y_train, X_test, y_test]:\n",
    "    print mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001\n",
      "lambda_loss_amount: 0.005\n",
      "\n",
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "features shape, labels shape, each features mean, each features standard deviation\n",
      "((9894, 24, 113), (9894, 18), 1.7156952e-05, 0.50001287)\n",
      "the dataset is therefore properly normalised, as expected.\n",
      "(24, ?, 113)\n",
      "(?, 113)\n",
      "(24, '(?, 113)')\n",
      "\n",
      "Creating hidden #1:\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "(24, '(?, 28)')\n",
      "\n",
      "Creating hidden #2:\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "(24, '(?, 28)')\n",
      "\n",
      "Creating hidden #3:\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "bidir:\n",
      "(24, '(?, 14)')\n",
      "(24, '(?, 28)')\n",
      "\n",
      "Unregularised variables:\n",
      "LSTM_network/layer_1/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/LSTM_residual_0/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/LSTM_residual_0/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/LSTM_residual_1/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/LSTM_residual_1/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_1/batch_norm/a_noreg:0\n",
      "LSTM_network/layer_1/batch_norm/b_noreg:0\n",
      "LSTM_network/layer_2/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/LSTM_residual_0/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/LSTM_residual_0/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/LSTM_residual_1/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/LSTM_residual_1/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/batch_norm/a_noreg:0\n",
      "LSTM_network/layer_2/batch_norm/b_noreg:0\n",
      "LSTM_network/layer_3/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/LSTM_residual_0/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/LSTM_residual_0/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/LSTM_residual_1/pass_forward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/LSTM_residual_1/pass_backward/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/batch_norm/a_noreg:0\n",
      "LSTM_network/layer_3/batch_norm/b_noreg:0\n",
      "LSTM_network/relu_fc_biases_noreg:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, train loss: 1.26639485359, train accuracy: 0.769999980927, train F1-score: 0.84154047619, test loss: 1.14398610592, test accuracy: 0.849302411079, test F1-score: 0.819828764792\n",
      "iter: 1, train loss: 0.913951992989, train accuracy: 0.849999904633, train F1-score: 0.854181625702, test loss: 0.908376812935, test accuracy: 0.845057368279, test F1-score: 0.842529909531\n",
      "iter: 2, train loss: 0.727368712425, train accuracy: 0.839999973774, train F1-score: 0.845345933264, test loss: 0.724536538124, test accuracy: 0.88023018837, test F1-score: 0.869155887342\n",
      "iter: 3, train loss: 0.694170475006, train accuracy: 0.859999895096, train F1-score: 0.822911371237, test loss: 0.720071196556, test accuracy: 0.863351345062, test F1-score: 0.862657299902\n",
      "iter: 4, train loss: 0.587053537369, train accuracy: 0.900000035763, train F1-score: 0.867452380952, test loss: 0.682242155075, test accuracy: 0.870830595493, test F1-score: 0.868958286763\n",
      "iter: 5, train loss: 0.550367534161, train accuracy: 0.860000014305, train F1-score: 0.949734767025, test loss: 0.636983275414, test accuracy: 0.873963773251, test F1-score: 0.872828086152\n",
      "iter: 6, train loss: 0.539011716843, train accuracy: 0.910000026226, train F1-score: 0.906291666667, test loss: 0.600761890411, test accuracy: 0.88407087326, test F1-score: 0.882915379094\n",
      "iter: 7, train loss: 0.521133184433, train accuracy: 0.900000035763, train F1-score: 0.89526795044, test loss: 0.59732657671, test accuracy: 0.882554829121, test F1-score: 0.880097419504\n",
      "iter: 8, train loss: 0.534667849541, train accuracy: 0.849999964237, train F1-score: 0.884366795367, test loss: 0.62351000309, test accuracy: 0.865979135036, test F1-score: 0.857400851567\n",
      "iter: 9, train loss: 0.475588321686, train accuracy: 0.870000004768, train F1-score: 0.881960784314, test loss: 0.558639347553, test accuracy: 0.888315916061, test F1-score: 0.885520146217\n",
      "iter: 10, train loss: 0.477295994759, train accuracy: 0.920000016689, train F1-score: 0.902698412698, test loss: 0.571366488934, test accuracy: 0.879017412663, test F1-score: 0.879309472079\n",
      "iter: 11, train loss: 0.544681549072, train accuracy: 0.860000014305, train F1-score: 0.850927318296, test loss: 0.56824016571, test accuracy: 0.873155236244, test F1-score: 0.872665527062\n",
      "iter: 12, train loss: 0.428999245167, train accuracy: 0.899999976158, train F1-score: 0.878239789196, test loss: 0.544777035713, test accuracy: 0.88386875391, test F1-score: 0.881929683514\n",
      "iter: 13, train loss: 0.423694163561, train accuracy: 0.910000026226, train F1-score: 0.870840277778, test loss: 0.559485971928, test accuracy: 0.87184125185, test F1-score: 0.874013295068\n",
      "iter: 14, train loss: 0.453907191753, train accuracy: 0.920000076294, train F1-score: 0.949974937343, test loss: 0.600412964821, test accuracy: 0.861633121967, test F1-score: 0.861945150519\n",
      "iter: 15, train loss: 0.441596776247, train accuracy: 0.910000085831, train F1-score: 0.845507030936, test loss: 0.639561295509, test accuracy: 0.844855189323, test F1-score: 0.857908769854\n",
      "iter: 16, train loss: 0.439582794905, train accuracy: 0.899999976158, train F1-score: 0.949915778252, test loss: 0.530400514603, test accuracy: 0.880735576153, test F1-score: 0.883614200444\n",
      "iter: 17, train loss: 0.439816087484, train accuracy: 0.920000076294, train F1-score: 0.913681181564, test loss: 0.551231920719, test accuracy: 0.865675926208, test F1-score: 0.869099878433\n",
      "iter: 18, train loss: 0.462134122849, train accuracy: 0.880000054836, train F1-score: 0.91715565032, test loss: 0.522455811501, test accuracy: 0.89074164629, test F1-score: 0.890571121312\n",
      "iter: 19, train loss: 0.355691403151, train accuracy: 0.920000016689, train F1-score: 0.905439324117, test loss: 0.507954716682, test accuracy: 0.890034139156, test F1-score: 0.889009833121\n",
      "iter: 20, train loss: 0.38616257906, train accuracy: 0.8900000453, train F1-score: 0.911713804714, test loss: 0.527525901794, test accuracy: 0.884778439999, test F1-score: 0.884410393184\n",
      "iter: 21, train loss: 0.420696914196, train accuracy: 0.909999966621, train F1-score: 0.92686351706, test loss: 0.54721570015, test accuracy: 0.871841311455, test F1-score: 0.875279730921\n",
      "iter: 22, train loss: 0.310894161463, train accuracy: 0.959999978542, train F1-score: 0.870594684385, test loss: 0.508252501488, test accuracy: 0.893268346786, test F1-score: 0.881518024098\n",
      "iter: 23, train loss: 0.366174697876, train accuracy: 0.920000076294, train F1-score: 0.914730922672, test loss: 0.506336033344, test accuracy: 0.891752421856, test F1-score: 0.888072816791\n",
      "iter: 24, train loss: 0.368320375681, train accuracy: 0.930000007153, train F1-score: 0.937786832854, test loss: 0.51013481617, test accuracy: 0.895087718964, test F1-score: 0.893066778623\n",
      "iter: 25, train loss: 0.34607064724, train accuracy: 0.900000035763, train F1-score: 0.957636363636, test loss: 0.530474543571, test accuracy: 0.880129158497, test F1-score: 0.874719182437\n",
      "iter: 26, train loss: 0.360716283321, train accuracy: 0.930000066757, train F1-score: 0.974424603175, test loss: 0.539702534676, test accuracy: 0.884576261044, test F1-score: 0.880789139767\n",
      "iter: 27, train loss: 0.384147822857, train accuracy: 0.910000026226, train F1-score: 0.88947922999, test loss: 0.535568714142, test accuracy: 0.885586977005, test F1-score: 0.883856900707\n",
      "iter: 28, train loss: 0.389809429646, train accuracy: 0.8900000453, train F1-score: 0.901285714286, test loss: 0.547228813171, test accuracy: 0.879825949669, test F1-score: 0.884031374368\n",
      "iter: 29, train loss: 0.445283949375, train accuracy: 0.870000004768, train F1-score: 0.924152693941, test loss: 0.536196529865, test accuracy: 0.879926919937, test F1-score: 0.882070375325\n",
      "iter: 30, train loss: 0.325052559376, train accuracy: 0.94000005722, train F1-score: 0.9182237784, test loss: 0.505438029766, test accuracy: 0.891550302505, test F1-score: 0.891439476416\n",
      "iter: 31, train loss: 0.445229679346, train accuracy: 0.920000016689, train F1-score: 0.909033794163, test loss: 0.604441642761, test accuracy: 0.855872035027, test F1-score: 0.866544444906\n",
      "iter: 32, train loss: 0.308753609657, train accuracy: 0.930000066757, train F1-score: 0.91944400527, test loss: 0.544644117355, test accuracy: 0.879118442535, test F1-score: 0.880610187042\n",
      "iter: 33, train loss: 0.284728229046, train accuracy: 0.950000047684, train F1-score: 0.917111111111, test loss: 0.49065464735, test accuracy: 0.893874883652, test F1-score: 0.890715826444\n",
      "iter: 34, train loss: 0.342547118664, train accuracy: 0.910000026226, train F1-score: 0.977474178404, test loss: 0.54289150238, test accuracy: 0.877804458141, test F1-score: 0.880152649195\n",
      "iter: 35, train loss: 0.324694991112, train accuracy: 0.930000007153, train F1-score: 0.925666666667, test loss: 0.52041041851, test accuracy: 0.889124512672, test F1-score: 0.886627463435\n",
      "iter: 36, train loss: 0.278797894716, train accuracy: 0.960000038147, train F1-score: 0.945475279107, test loss: 0.4825733006, test accuracy: 0.893975973129, test F1-score: 0.889865012873\n",
      "iter: 37, train loss: 0.354428976774, train accuracy: 0.920000016689, train F1-score: 0.925488780422, test loss: 0.579186975956, test accuracy: 0.875176727772, test F1-score: 0.875103151965\n",
      "iter: 38, train loss: 0.399466335773, train accuracy: 0.909999966621, train F1-score: 0.911946623094, test loss: 0.53322070837, test accuracy: 0.877501308918, test F1-score: 0.875711507436\n",
      "iter: 39, train loss: 0.277615517378, train accuracy: 0.94000005722, train F1-score: 0.932619047619, test loss: 0.543308019638, test accuracy: 0.879623770714, test F1-score: 0.881245627246\n",
      "iter: 40, train loss: 0.286434739828, train accuracy: 0.950000047684, train F1-score: 0.887214285714, test loss: 0.504517495632, test accuracy: 0.893268465996, test F1-score: 0.886764938984\n",
      "iter: 41, train loss: 0.311578512192, train accuracy: 0.930000066757, train F1-score: 0.929831932773, test loss: 0.516450166702, test accuracy: 0.888417005539, test F1-score: 0.885779329142\n",
      "iter: 42, train loss: 0.344402164221, train accuracy: 0.910000026226, train F1-score: 0.940928571429, test loss: 0.503110766411, test accuracy: 0.893874824047, test F1-score: 0.889287470187\n",
      "iter: 43, train loss: 0.333951294422, train accuracy: 0.930000066757, train F1-score: 0.952392694064, test loss: 0.498183578253, test accuracy: 0.888518095016, test F1-score: 0.88749563865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 44, train loss: 0.331044316292, train accuracy: 0.930000007153, train F1-score: 0.902623809524, test loss: 0.516022026539, test accuracy: 0.887204110622, test F1-score: 0.889722240372\n",
      "iter: 45, train loss: 0.349649071693, train accuracy: 0.920000076294, train F1-score: 0.944095238095, test loss: 0.524660348892, test accuracy: 0.886193454266, test F1-score: 0.882473954971\n",
      "iter: 46, train loss: 0.315815895796, train accuracy: 0.910000026226, train F1-score: 0.860568627451, test loss: 0.486249625683, test accuracy: 0.895896315575, test F1-score: 0.894202337284\n",
      "iter: 47, train loss: 0.233751118183, train accuracy: 0.960000038147, train F1-score: 0.911182072829, test loss: 0.50943249464, test accuracy: 0.88922560215, test F1-score: 0.888510459391\n",
      "iter: 48, train loss: 0.305129051208, train accuracy: 0.930000066757, train F1-score: 0.940606060606, test loss: 0.51904296875, test accuracy: 0.888113796711, test F1-score: 0.890891754451\n",
      "iter: 49, train loss: 0.26487866044, train accuracy: 0.939999997616, train F1-score: 0.994966442953, test loss: 0.538539648056, test accuracy: 0.887810587883, test F1-score: 0.884706387311\n",
      "iter: 50, train loss: 0.281741887331, train accuracy: 0.950000047684, train F1-score: 0.974964028777, test loss: 0.505739450455, test accuracy: 0.895593047142, test F1-score: 0.893466693765\n",
      "iter: 51, train loss: 0.302394539118, train accuracy: 0.930000007153, train F1-score: 0.903333333333, test loss: 0.519473612309, test accuracy: 0.890539526939, test F1-score: 0.885556555153\n",
      "iter: 52, train loss: 0.321120917797, train accuracy: 0.94000005722, train F1-score: 0.923619047619, test loss: 0.533305644989, test accuracy: 0.883767724037, test F1-score: 0.881533280981\n",
      "iter: 53, train loss: 0.336425900459, train accuracy: 0.930000007153, train F1-score: 0.954, test loss: 0.520990252495, test accuracy: 0.884475231171, test F1-score: 0.874947935213\n",
      "iter: 54, train loss: 0.365016311407, train accuracy: 0.939999997616, train F1-score: 0.946576441103, test loss: 0.542205572128, test accuracy: 0.878916323185, test F1-score: 0.881870154432\n",
      "iter: 55, train loss: 0.35141825676, train accuracy: 0.939999997616, train F1-score: 0.92833015873, test loss: 0.574590742588, test accuracy: 0.87052744627, test F1-score: 0.872389650186\n",
      "iter: 56, train loss: 0.327419936657, train accuracy: 0.930000066757, train F1-score: 0.91727006327, test loss: 0.536658942699, test accuracy: 0.878107726574, test F1-score: 0.875707517261\n",
      "iter: 57, train loss: 0.292863547802, train accuracy: 0.94000005722, train F1-score: 0.919572519084, test loss: 0.526127159595, test accuracy: 0.888113796711, test F1-score: 0.88162733491\n",
      "iter: 58, train loss: 0.28227263689, train accuracy: 0.94000005722, train F1-score: 0.940827067669, test loss: 0.557734251022, test accuracy: 0.878107726574, test F1-score: 0.876125530498\n",
      "iter: 59, train loss: 0.314013510942, train accuracy: 0.960000038147, train F1-score: 0.933829059829, test loss: 0.557923972607, test accuracy: 0.88235270977, test F1-score: 0.882292280871\n",
      "iter: 60, train loss: 0.337696075439, train accuracy: 0.930000007153, train F1-score: 0.952666666667, test loss: 0.55775231123, test accuracy: 0.877804517746, test F1-score: 0.880034960076\n",
      "iter: 61, train loss: 0.322748541832, train accuracy: 0.920000016689, train F1-score: 0.902432107798, test loss: 0.540990591049, test accuracy: 0.879017353058, test F1-score: 0.882837780452\n",
      "iter: 62, train loss: 0.280303925276, train accuracy: 0.930000007153, train F1-score: 0.885611499611, test loss: 0.513806164265, test accuracy: 0.890842735767, test F1-score: 0.891079955085\n",
      "iter: 63, train loss: 0.273845851421, train accuracy: 0.960000038147, train F1-score: 0.949433333333, test loss: 0.524801194668, test accuracy: 0.890337347984, test F1-score: 0.885633393311\n",
      "iter: 64, train loss: 0.338349491358, train accuracy: 0.930000007153, train F1-score: 0.933333333333, test loss: 0.50103610754, test accuracy: 0.896401643753, test F1-score: 0.894867923576\n",
      "iter: 65, train loss: 0.261750936508, train accuracy: 0.950000047684, train F1-score: 0.934044444444, test loss: 0.503650188446, test accuracy: 0.885991334915, test F1-score: 0.886180410466\n",
      "iter: 66, train loss: 0.313444972038, train accuracy: 0.930000066757, train F1-score: 0.928489812317, test loss: 0.547153413296, test accuracy: 0.878815233707, test F1-score: 0.879925540596\n",
      "iter: 67, train loss: 0.261450529099, train accuracy: 0.949999988079, train F1-score: 0.911911421911, test loss: 0.509079277515, test accuracy: 0.893975973129, test F1-score: 0.888930161145\n",
      "iter: 68, train loss: 0.275980681181, train accuracy: 0.94000005722, train F1-score: 0.938152380952, test loss: 0.541612148285, test accuracy: 0.884374141693, test F1-score: 0.884339097264\n",
      "iter: 69, train loss: 0.269645452499, train accuracy: 0.950000047684, train F1-score: 0.989320679321, test loss: 0.526056230068, test accuracy: 0.883868813515, test F1-score: 0.880805839905\n",
      "iter: 70, train loss: 0.293725252151, train accuracy: 0.950000047684, train F1-score: 0.954666666667, test loss: 0.541482329369, test accuracy: 0.891246974468, test F1-score: 0.885312104331\n",
      "iter: 71, train loss: 0.338032960892, train accuracy: 0.910000026226, train F1-score: 0.924731829574, test loss: 0.510497808456, test accuracy: 0.89094376564, test F1-score: 0.891504763026\n",
      "iter: 72, train loss: 0.229198992252, train accuracy: 0.980000019073, train F1-score: 0.958333333333, test loss: 0.555880308151, test accuracy: 0.882959187031, test F1-score: 0.883816546231\n",
      "iter: 73, train loss: 0.284660577774, train accuracy: 0.969999969006, train F1-score: 0.886545732874, test loss: 0.539486944675, test accuracy: 0.882757008076, test F1-score: 0.877597615976\n",
      "iter: 74, train loss: 0.320837557316, train accuracy: 0.930000007153, train F1-score: 0.943190779497, test loss: 0.568164944649, test accuracy: 0.880028069019, test F1-score: 0.876861574984\n",
      "iter: 75, train loss: 0.318525195122, train accuracy: 0.94000005722, train F1-score: 0.948761904762, test loss: 0.513724505901, test accuracy: 0.89417809248, test F1-score: 0.890418991092\n",
      "iter: 76, train loss: 0.252082526684, train accuracy: 0.94000005722, train F1-score: 0.921228381375, test loss: 0.520972549915, test accuracy: 0.889629781246, test F1-score: 0.888822505708\n",
      "iter: 77, train loss: 0.237678393722, train accuracy: 0.960000038147, train F1-score: 0.908211640212, test loss: 0.513870060444, test accuracy: 0.894582331181, test F1-score: 0.890038288885\n",
      "iter: 78, train loss: 0.274663388729, train accuracy: 0.910000026226, train F1-score: 0.941333333333, test loss: 0.554297685623, test accuracy: 0.87740021944, test F1-score: 0.875212310717\n",
      "iter: 79, train loss: 0.287992238998, train accuracy: 0.950000047684, train F1-score: 0.922877534469, test loss: 0.498006999493, test accuracy: 0.895390868187, test F1-score: 0.893386837923\n",
      "iter: 80, train loss: 0.306692957878, train accuracy: 0.930000066757, train F1-score: 0.946323232323, test loss: 0.514039874077, test accuracy: 0.886900901794, test F1-score: 0.885560168175\n",
      "iter: 81, train loss: 0.355193853378, train accuracy: 0.920000016689, train F1-score: 0.946, test loss: 0.55909371376, test accuracy: 0.890640556812, test F1-score: 0.884014756109\n",
      "iter: 82, train loss: 0.333755642176, train accuracy: 0.94000005722, train F1-score: 0.951182795699, test loss: 0.510066747665, test accuracy: 0.886496663094, test F1-score: 0.885246392537\n",
      "iter: 83, train loss: 0.301563113928, train accuracy: 0.910000026226, train F1-score: 0.933417249417, test loss: 0.501417458057, test accuracy: 0.894784510136, test F1-score: 0.889355206896\n",
      "iter: 84, train loss: 0.33863902092, train accuracy: 0.900000035763, train F1-score: 0.982088888889, test loss: 0.538064837456, test accuracy: 0.885890185833, test F1-score: 0.880529022149\n",
      "iter: 85, train loss: 0.29531365633, train accuracy: 0.930000066757, train F1-score: 0.971567328918, test loss: 0.532197713852, test accuracy: 0.887810647488, test F1-score: 0.882660385307\n",
      "iter: 86, train loss: 0.362862288952, train accuracy: 0.910000085831, train F1-score: 0.913666014351, test loss: 0.551665663719, test accuracy: 0.888315916061, test F1-score: 0.881688379747\n",
      "iter: 87, train loss: 0.2456677109, train accuracy: 0.960000038147, train F1-score: 0.943095238095, test loss: 0.526337146759, test accuracy: 0.891246974468, test F1-score: 0.887862100884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 88, train loss: 0.278152525425, train accuracy: 0.939999997616, train F1-score: 0.908290526316, test loss: 0.560994982719, test accuracy: 0.883565545082, test F1-score: 0.882805538387\n",
      "iter: 89, train loss: 0.239042714238, train accuracy: 0.939999997616, train F1-score: 0.969111111111, test loss: 0.539392650127, test accuracy: 0.887305140495, test F1-score: 0.889747065272\n",
      "iter: 90, train loss: 0.26443874836, train accuracy: 0.960000038147, train F1-score: 0.891424242424, test loss: 0.569280743599, test accuracy: 0.888821363449, test F1-score: 0.883503045043\n",
      "iter: 91, train loss: 0.273909270763, train accuracy: 0.950000047684, train F1-score: 0.928393341076, test loss: 0.5293597579, test accuracy: 0.889831960201, test F1-score: 0.888490449528\n",
      "iter: 92, train loss: 0.300491660833, train accuracy: 0.94000005722, train F1-score: 0.922977777778, test loss: 0.560269773006, test accuracy: 0.877096951008, test F1-score: 0.874528974264\n",
      "iter: 93, train loss: 0.28093034029, train accuracy: 0.949999988079, train F1-score: 0.94780141844, test loss: 0.522052407265, test accuracy: 0.882655918598, test F1-score: 0.87976711477\n",
      "iter: 94, train loss: 0.324229508638, train accuracy: 0.920000016689, train F1-score: 0.934830022075, test loss: 0.536470532417, test accuracy: 0.883363485336, test F1-score: 0.88304200999\n",
      "iter: 95, train loss: 0.296905517578, train accuracy: 0.900000035763, train F1-score: 0.927835574942, test loss: 0.514679372311, test accuracy: 0.886193394661, test F1-score: 0.887160437033\n",
      "iter: 96, train loss: 0.297697305679, train accuracy: 0.920000016689, train F1-score: 0.95183908046, test loss: 0.529711961746, test accuracy: 0.885283827782, test F1-score: 0.883322374133\n",
      "iter: 97, train loss: 0.241746991873, train accuracy: 0.959999978542, train F1-score: 0.961776155718, test loss: 0.53199839592, test accuracy: 0.883060216904, test F1-score: 0.884680297418\n",
      "iter: 98, train loss: 0.248066782951, train accuracy: 0.97000002861, train F1-score: 0.922246006867, test loss: 0.522449016571, test accuracy: 0.890842735767, test F1-score: 0.887370787129\n",
      "iter: 99, train loss: 0.363476753235, train accuracy: 0.920000016689, train F1-score: 0.901384615385, test loss: 0.540226101875, test accuracy: 0.881139814854, test F1-score: 0.880470501932\n",
      "\n",
      "final test accuracy: 0.881139814854\n",
      "best epoch's test accuracy: (0.89640164, 'iter: 64')\n",
      "final F1 score: 0.880470501932\n",
      "best epoch's F1 score: (0.89486792357619005, 'iter: 64')\n",
      "\n",
      "(0.88113981, (0.89640164, 'iter: 64'), 0.8804705019320257, (0.89486792357619005, 'iter: 64'))\n",
      "___________________\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "n_layers_in_highway = 3\n",
    "n_stacked_layers = 3\n",
    "trial_name = \"{}x{}\".format(n_layers_in_highway, n_stacked_layers)\n",
    "\n",
    "for learning_rate in [0.001]:\n",
    "    for lambda_loss_amount in [0.005]:\n",
    "        print \"learning_rate: {}\".format(learning_rate)\n",
    "        print \"lambda_loss_amount: {}\".format(lambda_loss_amount)\n",
    "        print \"\"\n",
    "\n",
    "        class EditedConfig(Config):\n",
    "            def __init__(self, X, Y):\n",
    "                super(EditedConfig, self).__init__(X, Y)\n",
    "\n",
    "                # Edit only some parameters:\n",
    "                self.learning_rate = learning_rate\n",
    "                self.lambda_loss_amount = lambda_loss_amount\n",
    "                # Architecture params:\n",
    "                self.n_layers_in_highway = n_layers_in_highway\n",
    "                self.n_stacked_layers = n_stacked_layers\n",
    "\n",
    "        accuracy_out, best_accuracy, f1_score_out, best_f1_score = \\\n",
    "                      run_with_config(EditedConfig, X_train, y_train, X_test, y_test)\n",
    "        print (accuracy_out, best_accuracy, f1_score_out, best_f1_score)\n",
    "\n",
    "        with open('{}_result_opportunity_18.txt'.format(trial_name),'a') as f:\n",
    "            \n",
    "            f.write(str(learning_rate)+' \\t'+str(lambda_loss_amount)+' \\t'+ \\\n",
    "                    str(accuracy_out)+' \\t'+str(best_accuracy)+' \\t'+\\\n",
    "                    str(f1_score_out)+' \\t'+str(best_f1_score)+'\\n\\n' )\n",
    "\n",
    "        print \"___________________\"\n",
    "    print \"\"\n",
    "print \"Done.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
