{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DeepConvLSTM is defined as a neural netowrk which combines convolutional and recurrent layers. The convolutional layers act as feature extractors and provide abstract representations of the input sensor data in feature maps. The recurrent layers model the temporal dynamics of the activation of the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cPickle as cp #serializing and de-serializing a Python object structure\n",
    "import theano.tensor as T\n",
    "from sliding_window import sliding_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.4)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# params setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "NUM_CLASSES = 18\n",
    "\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Length of the input sequence after convolutional operations\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Number filters convolutional layers\n",
    "NUM_FILTERS = 64\n",
    "\n",
    "# Size filters convolutional layers\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "# Number of unit in the long short-term recurrent layers\n",
    "NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load the OPPORTUNITY processed dataset. Sensor data is segmented using a sliding \n",
    "window of fixed length. The class associated with each segment corresponds to the \n",
    "gesture which has been observed during that interval. Given a sliding window of \n",
    "length T, we choose the class of the sequence as the label at t=T, or in other words, \n",
    "the label of last sample in the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      "after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n",
      "after sliding window (testing): inputs (9894, 24, 113, 1), targets (9894,)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = file(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
    "\n",
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, \n",
    "                                    SLIDING_WINDOW_STEP)\n",
    "print(\"after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, \n",
    "                                                                          y_test.shape))\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1))\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, \n",
    "                                      SLIDING_WINDOW_STEP)\n",
    "print(\"after sliding window (testing): inputs {0}, targets {1}\".format(\n",
    "                                      X_test.shape, y_test.shape))\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_train = X_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is ready\n"
     ]
    }
   ],
   "source": [
    "def one_hot(label):\n",
    "    \"\"\"convert label from dense to one hot\n",
    "      argument:\n",
    "        label: ndarray dense label ,shape: [sample_num,1]\n",
    "      return:\n",
    "        one_hot_label: ndarray  one hot, shape: [sample_num,n_class]\n",
    "    \"\"\"\n",
    "    label_num = len(label)\n",
    "    new_label = label.reshape(label_num)  # shape : [sample_num]\n",
    "    # because max is 5, and we will create 6 columns\n",
    "    n_values = np.max(new_label) + 1\n",
    "    return np.eye(n_values)[np.array(new_label, dtype=np.int32)]\n",
    "\n",
    "y_test=one_hot(y_test)\n",
    "y_train=one_hot(y_train)\n",
    "\n",
    "print(\"data is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def model(X, w, w2, w3, w4, rnnW, rnnB, lstm_size):\n",
    "    # l1a shape=(?, 28, 28, 32)\n",
    "    l1a = tf.nn.relu(tf.nn.conv2d(X, w, strides=[1, 1, 1, 1], padding='VALID'))\n",
    "    # l1 shape=(?, 14, 14, 32)\n",
    "    #l1 = tf.nn.max_pool(l1a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #l1 = tf.nn.dropout(l1, p_keep_conv)\n",
    "                     \n",
    "    # l2a shape=(?, 14, 14, 64)\n",
    "    l2a = tf.nn.relu(tf.nn.conv2d(l1a, w2, strides=[1, 1, 1, 1], padding='VALID'))\n",
    "    # l2 shape=(?, 7, 7, 64)\n",
    "    #l2 = tf.nn.max_pool(l2a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    #l2 = tf.nn.dropout(l2, p_keep_conv)\n",
    "\n",
    "    # l3a shape=(?, 7, 7, 128)\n",
    "    l3a = tf.nn.relu(tf.nn.conv2d(l2a, w3, strides=[1, 1, 1, 1], padding='VALID'))        \n",
    "    # l3 shape=(?, 4, 4, 128)                           \n",
    "    #l3 = tf.nn.max_pool(l3a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    # reshape to (?, 2048)\n",
    "    #l3 = tf.reshape(l3, [-1, w4.get_shape().as_list()[0]])  \n",
    "    #l3 = tf.nn.dropout(l3, p_keep_conv)\n",
    "                 \n",
    "    # l3a shape=(?, 7, 7, 128)\n",
    "    l4a = tf.nn.relu(tf.nn.conv2d(l3a, w4, strides=[1, 1, 1, 1], padding='VALID'))\n",
    "                     \n",
    "    shuff = tf.transpose(l4a, [1, 0, 2, 3])\n",
    "    shp1 = tf.reshape(shuff, [-1, lstm_size])\n",
    "    # split them to time_step_size (28 arrays)\n",
    "    X_split = tf.split(shp1, 452, 0) \n",
    "    \n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_size, \n",
    "                                        forget_bias=1.0, state_is_tuple=True)  \n",
    "    lstm_cell2 = tf.contrib.rnn.BasicLSTMCell(lstm_size, \n",
    "                                        forget_bias=1.0, state_is_tuple=True)\n",
    "    # Stack two LSTM layers, both layers has the same shape\n",
    "    lstm_layers = tf.contrib.rnn.MultiRNNCell([lstm_cell, lstm_cell2], \n",
    "                                              state_is_tuple=True)\n",
    "                     \n",
    "    outputs, _states = tf.contrib.rnn.static_rnn(lstm_layers, X_split, dtype=tf.float32)\n",
    "    #print(shp1.shape)\n",
    "    \n",
    "    print(\"tf net end\")\n",
    "\n",
    "    return tf.matmul(outputs[-1], rnnW) + rnnB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf net end\n",
      "get cnn output\n",
      "net work done\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, 24, 113, 1])\n",
    "Y = tf.placeholder(\"float\", [None, 18])\n",
    "\n",
    "lstm_size = 128\n",
    "w = init_weights([5, 1, 1, 64])       # 3x3x1 conv, 32 outputs\n",
    "w2 = init_weights([5, 1, 64, 64])     # 3x3x32 conv, 64 outputs\n",
    "w3 = init_weights([5, 1, 64, 64])    # 3x3x32 conv, 128 outputs\n",
    "w4 = init_weights([5, 1, 64, 64]) # FC 128 * 4 * 4 inputs, 625 outputs\n",
    "\n",
    "rnnW = init_weights([lstm_size, 18])\n",
    "rnnB = init_weights([18])\n",
    "pre_Y = model(X, w, w2, w3, w4, rnnW, rnnB,lstm_size)\n",
    "print (\"get cnn output\");\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pre_Y, labels=Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(pre_Y, 1)\n",
    "\n",
    "print(\"net work done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.85999999999999999)\n",
      "(1, 0.84999999999999998)\n",
      "(2, 0.80000000000000004)\n",
      "(3, 0.81999999999999995)\n",
      "(4, 0.81000000000000005)\n",
      "(5, 0.77000000000000002)\n",
      "(6, 0.92000000000000004)\n",
      "(7, 0.81999999999999995)\n",
      "(8, 0.75)\n",
      "(9, 0.81000000000000005)\n",
      "(10, 0.83999999999999997)\n",
      "(11, 0.82999999999999996)\n",
      "(12, 0.85999999999999999)\n",
      "(13, 0.80000000000000004)\n",
      "(14, 0.78000000000000003)\n",
      "(15, 0.84999999999999998)\n",
      "(16, 0.80000000000000004)\n",
      "(17, 0.82999999999999996)\n",
      "(18, 0.81000000000000005)\n",
      "(19, 0.81000000000000005)\n",
      "(20, 0.84999999999999998)\n",
      "(21, 0.87)\n",
      "(22, 0.87)\n",
      "(23, 0.84999999999999998)\n",
      "(24, 0.83999999999999997)\n",
      "(25, 0.77000000000000002)\n",
      "(26, 0.79000000000000004)\n",
      "(27, 0.79000000000000004)\n",
      "(28, 0.84999999999999998)\n",
      "(29, 0.85999999999999999)\n",
      "(30, 0.78000000000000003)\n",
      "(31, 0.87)\n",
      "(32, 0.83999999999999997)\n",
      "(33, 0.81000000000000005)\n",
      "(34, 0.78000000000000003)\n",
      "(35, 0.81000000000000005)\n",
      "(36, 0.81999999999999995)\n",
      "(37, 0.84999999999999998)\n",
      "(38, 0.81000000000000005)\n",
      "(39, 0.81000000000000005)\n",
      "(40, 0.85999999999999999)\n",
      "(41, 0.83999999999999997)\n",
      "(42, 0.81000000000000005)\n",
      "(43, 0.77000000000000002)\n",
      "(44, 0.84999999999999998)\n",
      "(45, 0.85999999999999999)\n",
      "(46, 0.82999999999999996)\n",
      "(47, 0.78000000000000003)\n",
      "(48, 0.81000000000000005)\n",
      "(49, 0.82999999999999996)\n",
      "(50, 0.85999999999999999)\n",
      "(51, 0.80000000000000004)\n",
      "(52, 0.89000000000000001)\n",
      "(53, 0.78000000000000003)\n",
      "(54, 0.76000000000000001)\n",
      "(55, 0.88)\n",
      "(56, 0.83999999999999997)\n",
      "(57, 0.87)\n",
      "(58, 0.87)\n",
      "(59, 0.76000000000000001)\n",
      "(60, 0.83999999999999997)\n",
      "(61, 0.85999999999999999)\n",
      "(62, 0.83999999999999997)\n",
      "(63, 0.84999999999999998)\n",
      "(64, 0.81000000000000005)\n",
      "(65, 0.80000000000000004)\n",
      "(66, 0.85999999999999999)\n",
      "(67, 0.83999999999999997)\n",
      "(68, 0.84999999999999998)\n",
      "(69, 0.87)\n",
      "(70, 0.82999999999999996)\n",
      "(71, 0.81000000000000005)\n",
      "(72, 0.85999999999999999)\n",
      "(73, 0.89000000000000001)\n",
      "(74, 0.87)\n",
      "(75, 0.83999999999999997)\n",
      "(76, 0.84999999999999998)\n",
      "(77, 0.77000000000000002)\n",
      "(78, 0.81999999999999995)\n",
      "(79, 0.87)\n",
      "(80, 0.76000000000000001)\n",
      "(81, 0.81000000000000005)\n",
      "(82, 0.88)\n",
      "(83, 0.81000000000000005)\n",
      "(84, 0.78000000000000003)\n",
      "(85, 0.87)\n",
      "(86, 0.81000000000000005)\n",
      "(87, 0.82999999999999996)\n",
      "(88, 0.81999999999999995)\n",
      "(89, 0.79000000000000004)\n",
      "(90, 0.82999999999999996)\n",
      "(91, 0.81000000000000005)\n",
      "(92, 0.80000000000000004)\n",
      "(93, 0.82999999999999996)\n",
      "(94, 0.81000000000000005)\n",
      "(95, 0.85999999999999999)\n",
      "(96, 0.87)\n",
      "(97, 0.89000000000000001)\n",
      "(98, 0.85999999999999999)\n",
      "(99, 0.88)\n"
     ]
    }
   ],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session(config=config) as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(X_train), BATCH_SIZE), \n",
    "                              range(BATCH_SIZE, len(X_train)+1, BATCH_SIZE)):\n",
    "            sess.run(train_op, feed_dict={X: X_train[start:end], Y: y_train[start:end]})\n",
    "\n",
    "        test_indices = np.arange(len(X_test))  # Get A Test Batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0: 100]\n",
    "\n",
    "        print(i, np.mean(np.argmax(y_test[test_indices], axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: X_test[test_indices]})))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
